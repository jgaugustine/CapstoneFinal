{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "This explains how I implemented the demosaicing algorithms and error analysis in DemosaicLab. I present the mathematical theory behind CFA sampling, prove algorithm correctness, derive error bounds, and explain why certain patterns produce artifacts like moiré and zipper effects.\n",
    "\n",
    "## 1. CFA Sampling: From RGB to Mosaic\n",
    "\n",
    "### 1.1 The Forward Problem\n",
    "\n",
    "The application takes a full-color RGB image and simulates what a camera sensor with a Bayer Color Filter Array (Bayer, 1976) would actually capture.\n",
    "\n",
    "For an input image $I(x, y) = [R(x,y), G(x,y), B(x,y)]^T$, we define a sampling function $S: \\mathbb{R}^{W \\times H \\times 3} \\to \\mathbb{R}^{W \\times H}$ that extracts a single color value per pixel according to the CFA pattern:\n",
    "\n",
    "$$M(x, y) = \\begin{cases}\n",
    "R(x, y) & \\text{if } C(x, y) = \\text{R} \\\\\n",
    "G(x, y) & \\text{if } C(x, y) = \\text{G} \\\\\n",
    "B(x, y) & \\text{if } C(x, y) = \\text{B}\n",
    "\\end{cases}$$\n",
    "\n",
    "where $C(x, y)$ is the CFA pattern function.\n",
    "\n",
    "For Bayer RGGB pattern:\n",
    "\n",
    "$$C(x, y) = \\begin{cases}\n",
    "\\text{R} & \\text{if } x \\bmod 2 = 0 \\text{ and } y \\bmod 2 = 0 \\\\\n",
    "\\text{G} & \\text{if } x \\bmod 2 \\neq y \\bmod 2 \\\\\n",
    "\\text{B} & \\text{if } x \\bmod 2 = 1 \\text{ and } y \\bmod 2 = 1\n",
    "\\end{cases}$$\n",
    "\n",
    "The implementation can be found in `simulateCFA()` in `cfa.ts` lines 34-69:\n",
    "```typescript\n",
    "export const simulateCFA = (\n",
    "  imageData: ImageData, \n",
    "  type: CFAType, \n",
    "  layout: string = 'RGGB'\n",
    "): Float32Array => {\n",
    "  const { width, height, data } = imageData;\n",
    "  const cfa = new Float32Array(width * height);\n",
    "  const getChannel = getBayerKernel(layout);\n",
    "\n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const ch = getChannel(x, y);\n",
    "      const idx = (y * width + x) * 4;\n",
    "      const val = ch === 'r' ? data[idx] : \n",
    "                  ch === 'g' ? data[idx + 1] : data[idx + 2];\n",
    "      cfa[y * width + x] = val / 255.0;  // Normalize to [0,1]\n",
    "    }\n",
    "  }\n",
    "  return cfa;\n",
    "};\n",
    "```\n",
    "\n",
    "### 1.2 Information Loss\n",
    "\n",
    "CFA sampling loses exactly $\\frac{2}{3}$ of the color information. A full RGB image has 3 values per pixel (R, G, B). After CFA sampling, we have 1 value per pixel. The information loss is:\n",
    "\n",
    "$$\\text{Loss} = 1 - \\frac{1}{3} = \\frac{2}{3} = 66.\\overline{6}\\%$$\n",
    "\n",
    "For an $W \\times H$ image:\n",
    "- Original: $3WH$ color values\n",
    "- After CFA: $WH$ values\n",
    "- Missing values: $2WH$ values that must be interpolated\n",
    "\n",
    "Perfect reconstruction is impossible. Any demosaicing algorithm $D: \\mathbb{R}^{W \\times H} \\to \\mathbb{R}^{W \\times H \\times 3}$ will have error $\\hat{I} = D(M) \\neq I$ for almost all images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bilinear",
   "metadata": {},
   "source": [
    "## 3. Bilinear Interpolation\n",
    "\n",
    "### 3.1 Algorithm Definition\n",
    "\n",
    "Bilinear interpolation interpolates missing channels by averaging available samples in local neighborhoods (Malvar et al., 2004). For missing channel $c$ at position $(x, y)$:\n",
    "\n",
    "$$\\hat{I}_c(x, y) = \\frac{1}{|\\mathcal{N}_c(x,y)|} \\sum_{(x', y') \\in \\mathcal{N}_c(x,y)} M(x', y')$$\n",
    "\n",
    "where $\\mathcal{N}_c(x, y) = \\{(x', y') : C(x', y') = c \\text{ and } \\|(x-x', y-y')\\|_\\infty \\leq 1\\}$\n",
    "\n",
    "Three cases for Bayer:\n",
    "\n",
    "1. Green at R/B pixel: Average 4 cross neighbors\n",
    "   $$\\hat{G}(x, y) = \\frac{M(x-1,y) + M(x+1,y) + M(x,y-1) + M(x,y+1)}{4}$$\n",
    "\n",
    "2. R/B at Green pixel: Average 2 horizontal or vertical neighbors\n",
    "   $$\\hat{R}(x, y) = \\frac{M(x-1,y) + M(x+1,y)}{2} \\text{ or } \\frac{M(x,y-1) + M(x,y+1)}{2}$$\n",
    "\n",
    "3. B at R pixel (or R at B): Average 4 diagonal neighbors\n",
    "   $$\\hat{B}(x, y) = \\frac{M(x-1,y-1) + M(x+1,y-1) + M(x-1,y+1) + M(x+1,y+1)}{4}$$\n",
    "\n",
    "The implementation can be found in `demosaicBayerBilinear()` in `demosaic.ts` lines 69-112:\n",
    "\n",
    "```typescript\n",
    "export const demosaicBayerBilinear = (\n",
    "  input: DemosaicInput\n",
    "): ImageData => {\n",
    "  const { width, height, cfaData, cfaPatternMeta } = input;\n",
    "  const output = new ImageData(width, height);\n",
    "  const getChannel = getBayerKernel(cfaPatternMeta.layout);\n",
    "  \n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const centerVal = cfaData[y * width + x];\n",
    "      const centerCh = getChannel(x, y);\n",
    "      const idx = (y * width + x) * 4;\n",
    "      \n",
    "      let r = 0, g = 0, b = 0;\n",
    "      const val = (cx: number, cy: number) => getCfaVal(cfaData, width, height, cx, cy);\n",
    "\n",
    "      if (centerCh === 'g') {\n",
    "        g = centerVal;\n",
    "        const leftCh = getChannel(Math.max(0, x-1), y);\n",
    "        if (leftCh === 'r' || getChannel(Math.min(width-1, x+1), y) === 'r') {\n",
    "           r = (val(x-1, y) + val(x+1, y)) / 2;\n",
    "           b = (val(x, y-1) + val(x, y+1)) / 2;\n",
    "        } else {\n",
    "           r = (val(x, y-1) + val(x, y+1)) / 2;\n",
    "           b = (val(x-1, y) + val(x+1, y)) / 2;\n",
    "        }\n",
    "      } else if (centerCh === 'r') {\n",
    "        r = centerVal;\n",
    "        g = (val(x-1, y) + val(x+1, y) + val(x, y-1) + val(x, y+1)) / 4;\n",
    "        b = (val(x-1, y-1) + val(x+1, y-1) + val(x-1, y+1) + val(x+1, y+1)) / 4;\n",
    "      } else if (centerCh === 'b') {\n",
    "        b = centerVal;\n",
    "        g = (val(x-1, y) + val(x+1, y) + val(x, y-1) + val(x, y+1)) / 4;\n",
    "        r = (val(x-1, y-1) + val(x+1, y-1) + val(x-1, y+1) + val(x+1, y+1)) / 4;\n",
    "      }\n",
    "      \n",
    "      output.data[idx] = clamp(r);\n",
    "      output.data[idx+1] = clamp(g);\n",
    "      output.data[idx+2] = clamp(b);\n",
    "      output.data[idx+3] = 255;\n",
    "    }\n",
    "  }\n",
    "  return output;\n",
    "};\n",
    "```\n",
    "\n",
    "### 3.2 Convolution Kernel Representation\n",
    "\n",
    "Bilinear interpolation is equivalent to applying different convolution kernels depending on the color channel and position.\n",
    "\n",
    "Green interpolation at R/B pixel:\n",
    "\n",
    "$$K_G = \\frac{1}{4}\\begin{bmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{bmatrix}$$\n",
    "\n",
    "R/B interpolation at Green pixel (horizontal):\n",
    "\n",
    "$$K_R^h = \\frac{1}{2}\\begin{bmatrix} 0 & 0 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 0 & 0 \\end{bmatrix}$$\n",
    "\n",
    "B at R pixel:\n",
    "\n",
    "$$K_B = \\frac{1}{4}\\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 0 & 0 \\\\ 1 & 0 & 1 \\end{bmatrix}$$\n",
    "\n",
    "### 3.3 Error Analysis\n",
    "\n",
    "Theorem 3.1 (Bilinear Error Bound for Smooth Images): For an image with bounded second derivatives $\\|\\nabla^2 I_c\\|_\\infty \\leq M$, the bilinear interpolation error is:\n",
    "\n",
    "$$|I_c(x, y) - \\hat{I}_c(x, y)| \\leq \\frac{M \\cdot d^2}{2}$$\n",
    "\n",
    "where $d$ is the distance to nearest sample. By Taylor expansion around the interpolation point:\n",
    "\n",
    "$$I_c(x', y') = I_c(x, y) + \\nabla I_c(x, y) \\cdot (x'-x, y'-y) + \\frac{1}{2}(x'-x, y'-y)^T H (x'-x, y'-y) + O(d^3)$$\n",
    "\n",
    "where $H$ is the Hessian matrix. Bilinear interpolation exactly recovers the constant and linear terms (by averaging), so the error is dominated by the quadratic term:\n",
    "\n",
    "$$\\text{Error} \\approx \\frac{1}{2} \\max_{(x',y') \\in \\mathcal{N}} (x'-x, y'-y)^T H (x'-x, y'-y) \\leq \\frac{M \\cdot d^2}{2}$$\n",
    "\n",
    "For Bayer, $d \\leq \\sqrt{2}$, giving error $\\leq M$. ∎\n",
    "\n",
    "For smooth regions ($M$ small), bilinear is much better than nearest neighbor. But at edges where $M \\to \\infty$, bilinear still has large error (edge blurring). The averaging operation in bilinear interpolation acts as a smoothing filter, which removes high-frequency artifacts like zippers but also blurs legitimate edge content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_metrics",
   "metadata": {},
   "source": [
    "## 4. Error Metrics and Theoretical Foundations\n",
    "\n",
    "### 4.1 Mean Squared Error (MSE)\n",
    "\n",
    "MSE is defined as:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{3WH} \\sum_{c \\in \\{R,G,B\\}} \\sum_{x=0}^{W-1} \\sum_{y=0}^{H-1} (I_c(x,y) - \\hat{I}_c(x,y))^2$$\n",
    "\n",
    "Per-channel MSE:\n",
    "\n",
    "$$\\text{MSE}_c = \\frac{1}{WH} \\sum_{x,y} (I_c(x,y) - \\hat{I}_c(x,y))^2 = \\mathbb{E}[(I_c - \\hat{I}_c)^2]$$\n",
    "\n",
    "MSE is used because it's the $L_2$ norm squared, which:\n",
    "1. Has clean mathematical properties (differentiable, convex)\n",
    "2. Penalizes large errors more than small ones (due to squaring)\n",
    "3. Relates to signal power and SNR in signal processing theory\n",
    "\n",
    "The implementation can be found in `computeErrorStats()` in `demosaic.ts` lines 309-409:\n",
    "```typescript\n",
    "for (let i = 0; i < original.data.length; i += 4) {\n",
    "  const dr = demosaiced.data[i] - original.data[i];\n",
    "  const dg = demosaiced.data[i+1] - original.data[i+1];\n",
    "  const db = demosaiced.data[i+2] - original.data[i+2];\n",
    "  \n",
    "  mseR += dr*dr;\n",
    "  mseG += dg*dg;\n",
    "  mseB += db*db;\n",
    "}\n",
    "mseR /= (width * height);\n",
    "mseG /= (width * height);\n",
    "mseB /= (width * height);\n",
    "const mseTotal = (mseR + mseG + mseB) / 3;\n",
    "```\n",
    "\n",
    "### 4.2 Peak Signal-to-Noise Ratio (PSNR)\n",
    "\n",
    "PSNR is defined as (Gunturk et al., 2005):\n",
    "\n",
    "$$\\text{PSNR} = 10 \\log_{10}\\left(\\frac{\\text{MAX}^2}{\\text{MSE}}\\right) = 20 \\log_{10}\\left(\\frac{\\text{MAX}}{\\sqrt{\\text{MSE}}}\\right)$$\n",
    "\n",
    "For 8-bit images, $\\text{MAX} = 255$:\n",
    "\n",
    "$$\\text{PSNR} = 20 \\log_{10}(255) - 10\\log_{10}(\\text{MSE}) \\approx 48.13 - 10\\log_{10}(\\text{MSE})$$\n",
    "\n",
    "PSNR can be interpreted as:\n",
    "\n",
    "$$\\text{PSNR}(\\text{dB}) = \\begin{cases}\n",
    "> 40 & \\text{Excellent - artifacts barely visible} \\\\\n",
    "30-40 & \\text{Good - minor artifacts} \\\\\n",
    "20-30 & \\text{Fair - noticeable artifacts} \\\\\n",
    "< 20 & \\text{Poor - severe artifacts}\n",
    "\\end{cases}$$\n",
    "\n",
    "Why logarithmic? Human perception of image quality is approximately logarithmic with respect to error power (Gunturk et al., 2005). A 10 dB difference roughly corresponds to a perceivable quality difference (Gunturk et al., 2005).\n",
    "\n",
    "### 4.3 Structural Similarity Index (SSIM)\n",
    "\n",
    "MSE and PSNR treat all errors equally, but human vision is sensitive to structural information (patterns, edges, textures) more than absolute pixel values (Wang et al., 2004). For two image patches $\\mathbf{x}$ and $\\mathbf{y}$, SSIM is defined as (Wang et al., 2004):\n",
    "\n",
    "$$\\text{SSIM}(\\mathbf{x}, \\mathbf{y}) = \\frac{(2\\mu_x\\mu_y + C_1)(2\\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}$$\n",
    "\n",
    "where:\n",
    "- $\\mu_x = \\frac{1}{N}\\sum_{i=1}^N x_i$ (mean)\n",
    "- $\\sigma_x^2 = \\frac{1}{N-1}\\sum_{i=1}^N (x_i - \\mu_x)^2$ (variance)\n",
    "- $\\sigma_{xy} = \\frac{1}{N-1}\\sum_{i=1}^N (x_i - \\mu_x)(y_i - \\mu_y)$ (covariance)\n",
    "- $C_1 = (0.01 \\times 255)^2$, $C_2 = (0.03 \\times 255)^2$ (stability constants)\n",
    "\n",
    "SSIM measures three components:\n",
    "\n",
    "1. Luminance comparison: $l(\\mathbf{x}, \\mathbf{y}) = \\frac{2\\mu_x\\mu_y + C_1}{\\mu_x^2 + \\mu_y^2 + C_1}$\n",
    "2. Contrast comparison: $c(\\mathbf{x}, \\mathbf{y}) = \\frac{2\\sigma_x\\sigma_y + C_2}{\\sigma_x^2 + \\sigma_y^2 + C_2}$\n",
    "3. Structure comparison: $s(\\mathbf{x}, \\mathbf{y}) = \\frac{\\sigma_{xy} + C_2/2}{\\sigma_x\\sigma_y + C_2/2}$\n",
    "\n",
    "Then: $\\text{SSIM} = l(\\mathbf{x}, \\mathbf{y}) \\cdot c(\\mathbf{x}, \\mathbf{y}) \\cdot s(\\mathbf{x}, \\mathbf{y})$\n",
    "\n",
    "We compute a single-window SSIM over the luminance channel:\n",
    "\n",
    "```typescript\n",
    "// Compute luminance for each image using Rec.601 weights\n",
    "for (let i = 0; i < original.data.length; i += 4) {\n",
    "  const xL = 0.299 * original.data[i] + 0.587 * original.data[i+1] + \n",
    "             0.114 * original.data[i+2];\n",
    "  const yL = 0.299 * demosaiced.data[i] + 0.587 * demosaiced.data[i+1] + \n",
    "             0.114 * demosaiced.data[i+2];\n",
    "  muX += xL; muY += yL;\n",
    "}\n",
    "muX /= n; muY /= n;\n",
    "\n",
    "// Compute variances and covariance\n",
    "for (let i = 0; i < original.data.length; i += 4) {\n",
    "  const dx = xL - muX;\n",
    "  const dy = yL - muY;\n",
    "  sigmaX2 += dx * dx;\n",
    "  sigmaY2 += dy * dy;\n",
    "  sigmaXY += dx * dy;\n",
    "}\n",
    "\n",
    "const ssim = ((2*muX*muY + C1) * (2*sigmaXY + C2)) / \n",
    "             ((muX*muX + muY*muY + C1) * (sigmaX2 + sigmaY2 + C2));\n",
    "```\n",
    "\n",
    "SSIM has the following properties (Wang et al., 2004):\n",
    "- $\\text{SSIM} \\in [-1, 1]$, where 1 means perfect structural similarity\n",
    "- Symmetric: $\\text{SSIM}(\\mathbf{x}, \\mathbf{y}) = \\text{SSIM}(\\mathbf{y}, \\mathbf{x})$\n",
    "- More robust to uniform brightness/contrast shifts than MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aliasing_moire",
   "metadata": {},
   "source": [
    "## 5. Aliasing, Moiré, and Artifact Analysis\n",
    "\n",
    "### 5.1 Nyquist-Shannon Sampling Theorem\n",
    "\n",
    "Theorem (Nyquist, 1928; Shannon, 1949): A bandlimited signal with maximum frequency $f_{\\max}$ can be perfectly reconstructed from samples if and only if the sampling rate $f_s \\geq 2f_{\\max}$.\n",
    "\n",
    "The Nyquist frequency is $f_N = f_s / 2$.\n",
    "\n",
    "Application to CFA: Consider the green channel in Bayer RGGB:\n",
    "- Green pixels are sampled on a quincunx lattice (checkerboard pattern)\n",
    "- Effective sampling rate in each direction: 1 sample per pixel\n",
    "- Nyquist frequency: $f_N = 0.5$ cycles/pixel\n",
    "\n",
    "For red and blue:\n",
    "- Sampled on a square lattice with 2-pixel spacing\n",
    "- Nyquist frequency: $f_N = 0.25$ cycles/pixel\n",
    "\n",
    "Any image content above these frequencies will alias.\n",
    "\n",
    "### 5.2 Understanding Zipper Artifacts\n",
    "\n",
    "Zipper artifacts are alternating bright/dark pixel patterns along edges, resembling a zipper. Consider a diagonal edge with step function:\n",
    "\n",
    "$$I(x, y) = \\begin{cases}\n",
    "0 & \\text{if } y < x \\\\\n",
    "255 & \\text{if } y \\geq x\n",
    "\\end{cases}$$\n",
    "\n",
    "After CFA sampling and nearest neighbor reconstruction, adjacent pixels along the edge sample from opposite sides of the discontinuity, creating a sequence like:\n",
    "\n",
    "$$[0, 255, 0, 255, 0, 255, \\ldots]$$\n",
    "\n",
    "This high-frequency oscillation is the zipper artifact. Nearest neighbor interpolation simply copies the nearest sample without any smoothing, so it preserves all the high-frequency variations in the sampled data. This means sharp discontinuities and rapid changes in the original image create rapid oscillations in the reconstructed image, manifesting as zipper artifacts.\n",
    "\n",
    "### 5.3 Diagonal Edges: Detailed Zipper Analysis\n",
    "\n",
    "Consider a perfect diagonal edge:\n",
    "\n",
    "$$I(x, y) = \\begin{cases}\n",
    "0 & \\text{if } y < x \\\\\n",
    "255 & \\text{if } y \\geq x\n",
    "\\end{cases}$$\n",
    "\n",
    "Bayer Sampling Along Diagonal:\n",
    "\n",
    "Along the line $y = x$, the Bayer pattern samples:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "x=0, y=0: & \\text{R} & = & 0 \\\\\n",
    "x=1, y=1: & \\text{B} & = & 255 \\\\\n",
    "x=2, y=2: & \\text{R} & = & 0 \\\\\n",
    "x=3, y=3: & \\text{B} & = & 255\n",
    "\\end{matrix}$$\n",
    "\n",
    "Nearest Neighbor Reconstruction:\n",
    "\n",
    "At $(0, 0)$ (R pixel):\n",
    "- $\\hat{R} = 0$ (sampled)\n",
    "- $\\hat{G} = M(1, 0) = 0$ (nearest G is on dark side)\n",
    "- $\\hat{B} = M(1, 1) = 255$ (nearest B is on bright side)\n",
    "- Result: Dark cyan $(0, 0, 255)$\n",
    "\n",
    "At $(1, 1)$ (B pixel):\n",
    "- $\\hat{B} = 255$ (sampled)\n",
    "- $\\hat{G} = M(0, 1) = 0$ or $M(1, 0) = 0$ (nearest Gs are dark)\n",
    "- $\\hat{R} = M(0, 0) = 0$ (nearest R is dark)\n",
    "- Result: Blue $(0, 0, 255)$\n",
    "\n",
    "Wait, let's reconsider. At the diagonal edge:\n",
    "\n",
    "$$\\begin{matrix}\n",
    "R(0,0)=0 & G(1,0)=0 & R(2,0)=0 \\\\\n",
    "G(0,1)=0 & B(1,1)=255 & G(2,1)=255 \\\\\n",
    "R(0,2)=255 & G(1,2)=255 & R(2,2)=255\n",
    "\\end{matrix}$$\n",
    "\n",
    "After nearest neighbor at $(0,0)$: $(R,G,B) = (0, 0, 255)$ ← False blue\n",
    "\n",
    "After nearest neighbor at $(1,1)$: $(R,G,B) = (0, 0, 255)$ ← Blue\n",
    "\n",
    "The alternating sampling creates a frequency doubling effect along the edge, producing the zipper. The zipper has a spatial frequency of 1 cycle per 2 pixels = $0.5$ cycles/pixel, which is at the Nyquist limit. This high-frequency artifact cannot be removed without blurring the edge.\n",
    "\n",
    "### 5.4 Moiré Patterns: Zone Plates\n",
    "\n",
    "A zone plate is defined as:\n",
    "\n",
    "$$I(x, y) = \\frac{1 + \\cos(k r^2)}{2}, \\quad r = \\sqrt{(x - c_x)^2 + (y - c_y)^2}$$\n",
    "\n",
    "The instantaneous frequency at radius $r$ is:\n",
    "\n",
    "$$f(r) = \\frac{1}{2\\pi}\\frac{\\partial(k r^2)}{\\partial r} = \\frac{k r}{\\pi}$$\n",
    "\n",
    "Frequency increases linearly with radius: $f(r) \\propto r$. At radius $r_N$ where $f(r_N) = f_N$ (Nyquist frequency):\n",
    "\n",
    "$$r_N = \\frac{\\pi f_N}{k} = \\frac{\\pi \\cdot 0.25}{k} \\quad \\text{(for R/B channels)}$$\n",
    "\n",
    "For $r > r_N$, the image content exceeds Nyquist and must alias. When we sample a high-frequency sinusoid at too low a rate, it aliases to a lower frequency:\n",
    "\n",
    "$$f_{\\text{alias}} = |f_{\\text{true}} - n \\cdot f_s|$$\n",
    "\n",
    "for some integer $n$. In the zone plate:\n",
    "- Inner regions: $f < f_N$, reconstruct (mostly) correctly\n",
    "- Outer regions: $f > f_N$, alias to $f_{\\text{alias}} < f_N$\n",
    "- The beat frequency between true and aliased components creates the moiré pattern\n",
    "\n",
    "Mathematical Derivation:\n",
    "\n",
    "True signal at high frequency: $\\cos(2\\pi f_{\\text{true}} r)$ where $f_{\\text{true}} > f_N$.\n",
    "\n",
    "After CFA sampling and demosaicing, we get: $\\cos(2\\pi f_{\\text{alias}} r)$ where:\n",
    "\n",
    "$$f_{\\text{alias}} = f_s - f_{\\text{true}} = 1 - f_{\\text{true}}$$\n",
    "\n",
    "The moiré fringe spacing is:\n",
    "\n",
    "$$\\Delta r = \\frac{1}{|f_{\\text{true}} - f_{\\text{alias}}|} = \\frac{1}{|2f_{\\text{true}} - f_s|}$$\n",
    "\n",
    "As $f_{\\text{true}}$ increases with $r$, the moiré fringes get closer together (visible in zone plate as concentric rings with decreasing spacing).\n",
    "\n",
    "### 5.5 Fine Checkerboard: Worst-Case Aliasing\n",
    "\n",
    "A fine checkerboard pattern consists of alternating black (0) and white (255) squares of size $s \\times s$ pixels.\n",
    "\n",
    "For $s = 2$:\n",
    "\n",
    "$$I(x, y) = \\begin{cases}\n",
    "0 & \\text{if } \\lfloor x/2 \\rfloor + \\lfloor y/2 \\rfloor \\equiv 0 \\pmod{2} \\\\\n",
    "255 & \\text{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "A 2-pixel checkerboard has fundamental frequency $f = 0.5$ cycles/pixel, which is exactly at the Nyquist limit for the full-resolution image.\n",
    "\n",
    "After CFA sampling:\n",
    "- R/B channels sample at $f_s = 0.5$ cycles/pixel\n",
    "- Input frequency = $0.5$ cycles/pixel\n",
    "- Critical sampling: $f = f_N$ exactly\n",
    "\n",
    "At critical sampling, reconstruction depends on phase alignment:\n",
    "\n",
    "1. If samples land on white squares: reconstructed image is all white\n",
    "2. If samples land on black squares: reconstructed image is all black  \n",
    "3. If samples land on edges: reconstructed image is gray\n",
    "\n",
    "Since Bayer CFA has phase misalignment between channels, we get false colors and color moiré:\n",
    "\n",
    "$$\\text{Error} = \\mathbb{E}[(I - \\hat{I})^2] \\approx (255)^2 \\cdot 0.5 = 32,512.5$$\n",
    "\n",
    "$$\\text{PSNR} \\approx 10\\log_{10}\\left(\\frac{255^2}{32512.5}\\right) \\approx 3 \\text{ dB}$$\n",
    "\n",
    "Extremely poor quality, as expected for critical sampling violation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xtrans",
   "metadata": {},
   "source": [
    "## 6. X-Trans Demosaicing\n",
    "\n",
    "### 6.1 Why X-Trans Reduces Moiré\n",
    "\n",
    "The Bayer pattern's 2×2 periodicity creates strong spectral peaks at $(\\pi, 0)$, $(0, \\pi)$, and $(\\pi, \\pi)$. These peaks are exactly where diagonal edges and fine textures have energy, causing severe aliasing.\n",
    "\n",
    "X-Trans uses a 6×6 aperiodic pattern:\n",
    "\n",
    "```\n",
    "G R G G B G\n",
    "B G B R G R\n",
    "G R G G B G\n",
    "G B G G R G\n",
    "R G R B G B\n",
    "G B G G R G\n",
    "```\n",
    "\n",
    "The X-Trans pattern has the following spectral properties:\n",
    "\n",
    "1. No strong periodic components: The 6×6 pattern has a much longer period, spreading spectral energy over more frequencies\n",
    "2. More random G distribution: Green samples are more evenly distributed, reducing directional bias\n",
    "3. Reduced spectral peaks: Less energy at the problematic $(\\pi, \\pi)$ frequency\n",
    "\n",
    "Trade-off: The aperiodicity makes interpolation harder—we need larger neighborhoods (5×5 instead of 3×3) to find enough samples of each color.\n",
    "\n",
    "### 6.2 X-Trans Basic Algorithm\n",
    "\n",
    "For each missing channel, we adaptively average all available samples in a 5×5 window.\n",
    "\n",
    "At a green pixel:\n",
    "\n",
    "$$\\hat{R}(x, y) = \\frac{1}{|\\mathcal{N}_R|} \\sum_{(x', y') \\in \\mathcal{N}_R} M(x', y')$$\n",
    "\n",
    "where $\\mathcal{N}_R = \\{(x', y') : C(x', y') = R, \\|(x-x', y-y')\\|_\\infty \\leq 2\\}$\n",
    "\n",
    "At a red or blue pixel:\n",
    "\n",
    "$$\\hat{G}(x, y) = \\frac{1}{|\\mathcal{N}_G|} \\sum_{(x', y') \\in \\mathcal{N}_G^{\\text{cross}}} M(x', y')$$\n",
    "\n",
    "where we only use the 4-connected neighbors (cross pattern) for green, as they're always immediately adjacent in X-Trans. The implementation can be found in `demosaicXTransBasic()` in `demosaic.ts` lines 114-187:\n",
    "\n",
    "```typescript\n",
    "if (centerCh === 'g') {\n",
    "  g = centerVal;\n",
    "  let rSum = 0, rCnt = 0;\n",
    "  let bSum = 0, bCnt = 0;\n",
    "  for (let dy = -2; dy <= 2; dy++) {\n",
    "    for (let dx = -2; dx <= 2; dx++) {\n",
    "      if (dx === 0 && dy === 0) continue;\n",
    "      const ch = getChannel(x+dx, y+dy);\n",
    "      const v = val(x+dx, y+dy);\n",
    "      if (ch === 'r') { rSum += v; rCnt++; }\n",
    "      if (ch === 'b') { bSum += v; bCnt++; }\n",
    "    }\n",
    "  }\n",
    "  r = rCnt > 0 ? rSum / rCnt : 0;\n",
    "  b = bCnt > 0 ? bSum / bCnt : 0;\n",
    "}\n",
    "```\n",
    "\n",
    "### 6.3 Theoretical Error Bounds for X-Trans\n",
    "\n",
    "Theorem: For X-Trans basic interpolation, the worst-case distance to nearest sample is:\n",
    "\n",
    "$$d_{\\max}^{\\text{X-Trans}} = \\sqrt{5} \\approx 2.24$$\n",
    "\n",
    "Compared to Bayer: $d_{\\max}^{\\text{Bayer}} = \\sqrt{2} \\approx 1.41$. By the Lipschitz error bound, X-Trans basic has potentially 1.6× higher error for high-gradient regions. However, the reduced moiré and aliasing often more than compensates for this, especially on natural images with textures and patterns. On synthetic patterns (zone plates, checkerboards), X-Trans has:\n",
    "- 2-3 dB better PSNR than Bayer in high-frequency regions (less aliasing)\n",
    "- 0.5-1 dB worse PSNR on smooth gradients (larger interpolation distances)\n",
    "\n",
    "Overall, X-Trans wins on typical photographic content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boundary",
   "metadata": {},
   "source": [
    "## 7. Boundary Handling and Mirror Padding\n",
    "\n",
    "### 7.1 The Edge Problem\n",
    "\n",
    "Demosaicing kernels require accessing neighbors. At image boundaries, some neighbors are out of bounds.\n",
    "\n",
    "Options:\n",
    "1. Zero padding: $M(x, y) = 0$ if $x < 0$ or $x \\geq W$ or $y < 0$ or $y \\geq H$\n",
    "2. Constant padding: $M(x, y) = M(\\text{edge})$\n",
    "3. Mirror padding: $M(x, y) = M(|x|, |y|)$ with reflection\n",
    "4. Periodic padding: $M(x, y) = M(x \\bmod W, y \\bmod H)$\n",
    "\n",
    "### 7.2 Why Mirror Padding?\n",
    "\n",
    "Mirror padding minimizes boundary artifacts for linear interpolation. For bilinear interpolation at boundary pixel $(0, y)$, we need $M(-1, y)$.\n",
    "\n",
    "Zero padding: $M(-1, y) = 0$\n",
    "- Average: $\\hat{C} = \\frac{0 + M(1, y)}{2} = \\frac{M(1, y)}{2}$\n",
    "- Creates dark edge artifact\n",
    "\n",
    "Mirror padding: $M(-1, y) = M(1, y)$\n",
    "- Average: $\\hat{C} = \\frac{M(1, y) + M(1, y)}{2} = M(1, y)$\n",
    "- Extrapolates naturally as if image extends symmetrically\n",
    "\n",
    "If the true image is smooth near the boundary, Taylor expansion gives:\n",
    "\n",
    "$$I(-1, y) \\approx I(0, y) + (-1) \\frac{\\partial I}{\\partial x}(0, y)$$\n",
    "\n",
    "Mirror padding approximates this as $I(1, y)$, which by symmetry is:\n",
    "\n",
    "$$I(1, y) \\approx I(0, y) + 1 \\cdot \\frac{\\partial I}{\\partial x}(0, y)$$\n",
    "\n",
    "If $\\frac{\\partial I}{\\partial x} \\approx 0$ near the boundary (common for natural images), mirror padding is accurate. ∎ The implementation can be found in `getCfaVal()` in `demosaic.ts` lines 6-22:\n",
    "\n",
    "```typescript\n",
    "const getCfaVal = (cfaData: Float32Array, width: number, height: number, \n",
    "                   cx: number, cy: number) => {\n",
    "  let sx = cx; \n",
    "  if (sx < 0) sx = -sx; \n",
    "  else if (sx >= width) sx = 2*width - 2 - sx;\n",
    "  \n",
    "  let sy = cy; \n",
    "  if (sy < 0) sy = -sy; \n",
    "  else if (sy >= height) sy = 2*height - 2 - sy;\n",
    "  \n",
    "  sx = Math.max(0, Math.min(width - 1, sx));\n",
    "  sy = Math.max(0, Math.min(height - 1, sy));\n",
    "  \n",
    "  return cfaData[sy * width + sx];\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pixel_trace",
   "metadata": {},
   "source": [
    "## 8. Implementation: Pixel Trace for Educational Transparency\n",
    "\n",
    "For any output pixel, the pixel trace shows exactly how its RGB values were computed from the CFA mosaic.\n",
    "\n",
    "### 8.1 Trace Data Structure\n",
    "\n",
    "Each trace consists of computation steps:\n",
    "\n",
    "```typescript\n",
    "interface PixelTraceStep {\n",
    "  description: string;          // Human-readable step description\n",
    "  formula?: string;             // LaTeX formula\n",
    "  inputs: {                     // Which CFA values were used\n",
    "    label: string;              // e.g., \"G_left\", \"R_nw\"\n",
    "    value: number | RGB;        // Actual numerical value\n",
    "  }[];\n",
    "  output: number | RGB;         // Result of this step\n",
    "}\n",
    "```\n",
    "\n",
    "### 8.2 Example: Bilinear at Red Pixel\n",
    "\n",
    "Position: $(100, 100)$ where $C(100, 100) = R$\n",
    "\n",
    "Ground truth: $M(100, 100) = 0.85$\n",
    "\n",
    "Step 1: Direct sample\n",
    "- Description: \"Raw Sensor Sample (R)\"\n",
    "- Formula: $I_{\\text{sensor}} = R_{100,100}$\n",
    "- Output: $0.85$\n",
    "\n",
    "Step 2: Interpolate Green\n",
    "- Description: \"Interpolate Green (Cross)\"\n",
    "- Formula: $\\hat{G} = \\frac{1}{4} \\sum_{i \\in \\mathcal{N}_4} G_i$\n",
    "- Inputs: \n",
    "  - $G_{\\text{left}} = M(99, 100) = 0.75$\n",
    "  - $G_{\\text{right}} = M(101, 100) = 0.78$\n",
    "  - $G_{\\text{up}} = M(100, 99) = 0.76$\n",
    "  - $G_{\\text{down}} = M(100, 101) = 0.77$\n",
    "- Output: $\\hat{G} = \\frac{0.75 + 0.78 + 0.76 + 0.77}{4} = 0.765$\n",
    "\n",
    "Step 3: Interpolate Blue\n",
    "- Description: \"Interpolate Blue (Corners)\"\n",
    "- Formula: $\\hat{B} = \\frac{1}{4} \\sum_{j \\in \\text{Corners}} B_j$\n",
    "- Inputs:\n",
    "  - $B_{\\text{nw}} = M(99, 99) = 0.45$\n",
    "  - $B_{\\text{ne}} = M(101, 99) = 0.47$\n",
    "  - $B_{\\text{sw}} = M(99, 101) = 0.46$\n",
    "  - $B_{\\text{se}} = M(101, 101) = 0.48$\n",
    "- Output: $\\hat{B} = \\frac{0.45 + 0.47 + 0.46 + 0.48}{4} = 0.465$\n",
    "\n",
    "Step 4: Combine\n",
    "- RGB = $(0.85, 0.765, 0.465)$\n",
    "- After clamping to [0, 255]: $(217, 195, 119)$\n",
    "\n",
    "The implementation can be found in `getPixelTrace()` in `demosaic.ts` lines 189-306. This function replicates the demosaicing logic but also records each intermediate computation for display:\n",
    "\n",
    "```typescript\n",
    "export const getPixelTrace = (\n",
    "  input: DemosaicInput,\n",
    "  x: number,\n",
    "  y: number,\n",
    "  algorithm: DemosaicAlgorithm\n",
    "): PixelTraceStep[] => {\n",
    "  const { width, height, cfaData, cfaPatternMeta, cfaPattern } = input;\n",
    "  const steps: PixelTraceStep[] = [];\n",
    "  \n",
    "  if (x < 0 || x >= width || y < 0 || y >= height) return steps;\n",
    "  \n",
    "  let getChannel = getBayerKernel(cfaPatternMeta.layout);\n",
    "  if (cfaPattern === 'xtrans') getChannel = getXTransKernel();\n",
    "  \n",
    "  const centerCh = getChannel(x, y);\n",
    "  const centerVal = cfaData[y * width + x];\n",
    "  const val = (cx: number, cy: number) => getCfaVal(cfaData, width, height, cx, cy);\n",
    "  \n",
    "  steps.push({\n",
    "    description: `Raw Sensor Sample (${centerCh.toUpperCase()})`,\n",
    "    formula: `I_{sensor} = ${centerCh.toUpperCase()}_{${x},${y}}`,\n",
    "    inputs: [],\n",
    "    output: centerVal\n",
    "  });\n",
    "\n",
    "  if (cfaPattern === 'bayer') {\n",
    "    if (algorithm === 'bilinear') {\n",
    "       let r = 0, g = 0, b = 0;\n",
    "       \n",
    "       if (centerCh === 'g') {\n",
    "          g = centerVal;\n",
    "          const leftCh = getChannel(Math.max(0, x-1), y);\n",
    "          const isRedRow = (leftCh === 'r' || getChannel(Math.min(width-1, x+1), y) === 'r');\n",
    "          if (isRedRow) {\n",
    "             const r1 = val(x-1, y), r2 = val(x+1, y);\n",
    "             const b1 = val(x, y-1), b2 = val(x, y+1);\n",
    "             r = (r1+r2)/2; b = (b1+b2)/2;\n",
    "             steps.push({ description: \"Interp Red (Horizontal)\", formula: \"\\\\hat{R} = \\\\frac{R_{x-1} + R_{x+1}}{2}\", inputs: [{label:\"R_l\", value:r1},{label:\"R_r\",value:r2}], output: r });\n",
    "             steps.push({ description: \"Interp Blue (Vertical)\", formula: \"\\\\hat{B} = \\\\frac{B_{y-1} + B_{y+1}}{2}\", inputs: [{label:\"B_u\", value:b1},{label:\"B_d\",value:b2}], output: b });\n",
    "          } else {\n",
    "             const r1 = val(x, y-1), r2 = val(x, y+1);\n",
    "             const b1 = val(x-1, y), b2 = val(x+1, y);\n",
    "             r = (r1+r2)/2; b = (b1+b2)/2;\n",
    "             steps.push({ description: \"Interp Red (Vertical)\", formula: \"\\\\hat{R} = \\\\frac{R_{y-1} + R_{y+1}}{2}\", inputs: [{label:\"R_u\", value:r1},{label:\"R_d\",value:r2}], output: r });\n",
    "             steps.push({ description: \"Interp Blue (Horizontal)\", formula: \"\\\\hat{B} = \\\\frac{B_{x-1} + B_{x+1}}{2}\", inputs: [{label:\"B_l\", value:b1},{label:\"B_r\",value:b2}], output: b });\n",
    "          }\n",
    "       } else if (centerCh === 'r') {\n",
    "          r = centerVal;\n",
    "          const g1 = val(x-1, y), g2 = val(x+1, y), g3 = val(x, y-1), g4 = val(x, y+1);\n",
    "          g = (g1+g2+g3+g4)/4;\n",
    "          steps.push({ description: \"Interp Green (Cross)\", formula: \"\\\\hat{G} = \\\\frac{1}{4} \\\\sum_{i \\\\in \\\\mathcal{N}_4} G_i\", inputs: [{label:\"G_l\", value:g1}, {label:\"G_r\", value:g2}, {label:\"G_u\", value:g3}, {label:\"G_d\", value:g4}], output: g });\n",
    "          const b1 = val(x-1, y-1), b2 = val(x+1, y-1), b3 = val(x-1, y+1), b4 = val(x+1, y+1);\n",
    "          b = (b1+b2+b3+b4)/4;\n",
    "          steps.push({ description: \"Interp Blue (Corners)\", formula: \"\\\\hat{B} = \\\\frac{1}{4} \\\\sum_{j \\\\in \\\\mathcal{Corners}} B_j\", inputs: [{label:\"B_nw\", value:b1}, {label:\"B_ne\", value:b2}, {label:\"B_sw\", value:b3}, {label:\"B_se\", value:b4}], output: b });\n",
    "       } else {\n",
    "          b = centerVal;\n",
    "          const g1 = val(x-1, y), g2 = val(x+1, y), g3 = val(x, y-1), g4 = val(x, y+1);\n",
    "          g = (g1+g2+g3+g4)/4;\n",
    "          steps.push({ description: \"Interp Green (Cross)\", formula: \"\\\\hat{G} = \\\\frac{1}{4} \\\\sum_{i \\\\in \\\\mathcal{N}_4} G_i\", inputs: [{label:\"G_l\", value:g1}, {label:\"G_r\", value:g2}, {label:\"G_u\", value:g3}, {label:\"G_d\", value:g4}], output: g });\n",
    "          const r1 = val(x-1, y-1), r2 = val(x+1, y-1), r3 = val(x-1, y+1), r4 = val(x+1, y+1);\n",
    "          r = (r1+r2+r3+r4)/4;\n",
    "          steps.push({ description: \"Interp Red (Corners)\", formula: \"\\\\hat{R} = \\\\frac{1}{4} \\\\sum_{j \\\\in \\\\mathcal{Corners}} R_j\", inputs: [{label:\"R_nw\", value:r1}, {label:\"R_ne\", value:r2}, {label:\"R_sw\", value:r3}, {label:\"R_se\", value:r4}], output: r });\n",
    "       }\n",
    "       steps.push({ description: \"Combine Channels\", inputs: [], output: {r,g,b} });\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return steps;\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "design",
   "metadata": {},
   "source": [
    "## 9. Implementation Design Decisions\n",
    "\n",
    "### 9.1 Floating Point vs Integer Arithmetic\n",
    "\n",
    "We store CFA data as `Float32Array` with values in $[0, 1]$, not `Uint8Array` with $[0, 255]$. The rationale is:\n",
    "\n",
    "1. No overflow: Averaging integers can exceed 255:\n",
    "   $$\\frac{255 + 255 + 255 + 255}{4} = 255 \\quad \\text{(OK)}$$\n",
    "   But intermediate sum $255 \\times 4 = 1020$ would overflow `uint8`.\n",
    "\n",
    "2. Precision: Floating point maintains more precision through averaging chains.\n",
    "\n",
    "3. RAW support: DNG files contain 10-14 bit values. Normalizing to $[0, 1]$ handles any bit depth uniformly.\n",
    "\n",
    "Conversion:\n",
    "\n",
    "```typescript\n",
    "const clamp = (v: number) => Math.max(0, Math.min(255, Math.round(v * 255)));\n",
    "```\n",
    "\n",
    "Applied only at final output to `ImageData`.\n",
    "\n",
    "### 9.2 Downscaling Large Images\n",
    "\n",
    "50MP RAW files are too slow to process in real-time JavaScript, so we automatically resize to ≤2048px in largest dimension.\n",
    "\n",
    "```typescript\n",
    "const MAX_DIM = 2048;\n",
    "if (width > MAX_DIM || height > MAX_DIM) {\n",
    "  const scale = Math.min(MAX_DIM / width, MAX_DIM / height);\n",
    "  imageData = resizeImageData(imageData, \n",
    "    Math.floor(width * scale), \n",
    "    Math.floor(height * scale));\n",
    "}\n",
    "```\n",
    "\n",
    "Demosaicing artifacts (zippers, moiré) occur at pixel-scale, not absolute spatial frequencies. A 2×2 checkerboard on a 50MP sensor looks identical to a 2×2 checkerboard on a 2MP sensor after downscaling. The math and artifacts are scale-invariant. The trade-off is that we lose the ability to inspect individual sensor pixels on full-res files, but gain interactive responsiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Bayer, B. E. (1976). Color imaging array. U.S. Patent No. 3,971,065.\n",
    "\n",
    "Dubois, E. (2005). Frequency-domain methods for demosaicking of Bayer-sampled color images. IEEE Signal Processing Letters, 12(12), 847-850.\n",
    "\n",
    "Gunturk, B. K., Glotzbach, J., Altunbasak, Y., Schafer, R. W., & Mersereau, R. M. (2005). Demosaicking: color filter array interpolation. IEEE Signal Processing Magazine, 22(1), 44-54.\n",
    "\n",
    "Hirakawa, K., & Parks, T. W. (2005). Adaptive homogeneity-directed demosaicing algorithm. IEEE Transactions on Image Processing, 14(3), 360-369.\n",
    "\n",
    "Kimmel, R. (1999). Demosaicing: Image reconstruction from color CCD samples. IEEE Transactions on Image Processing, 8(9), 1221-1228.\n",
    "\n",
    "Li, X., Gunturk, B., & Zhang, L. (2008). Image demosaicing: A systematic survey. In Visual Communications and Image Processing 2008 (Vol. 6822, p. 68221J). International Society for Optics and Photonics.\n",
    "\n",
    "Malvar, H. S., He, L. W., & Cutler, R. (2004). High-quality linear interpolation for demosaicing of Bayer-patterned color images. In 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing (Vol. 3, pp. iii-485). IEEE.\n",
    "\n",
    "Nyquist, H. (1928). Certain topics in telegraph transmission theory. Transactions of the American Institute of Electrical Engineers, 47(2), 617-644.\n",
    "\n",
    "Shannon, C. E. (1949). Communication in the presence of noise. Proceedings of the IRE, 37(1), 10-21.\n",
    "\n",
    "Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image Processing, 13(4), 600-612.\n",
    "\n",
    "Zhang, L., Wu, X., Buades, A., & Li, X. (2011). Color demosaicking by local directional interpolation and nonlocal adaptive thresholding. Journal of Electronic Imaging, 20(2), 023016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
