{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "This explains how I implemented the demosaicing algorithms and error analysis in DemosaicLab. I present the mathematical theory behind CFA sampling, present and explain the algorithms, and derive error bounds.\n",
    "\n",
    "\n",
    "## 1. CFA Sampling\n",
    "\n",
    "### 1.1 Bayer\n",
    "\n",
    "The application takes a full-color RGB image and simulates what a camera sensor with a Bayer Color Filter Array (Bayer, 1976) would actually capture.\n",
    "\n",
    "For an input image $I(x, y) = [R(x,y), G(x,y), B(x,y)]^T$, we define a sampling function $S: \\mathbb{R}^{W \\times H \\times 3} \\to \\mathbb{R}^{W \\times H}$ that extracts a single color value per pixel according to the CFA pattern:\n",
    "\n",
    "$$M(x, y) = \\begin{cases}\n",
    "R(x, y) & \\text{if } C(x, y) = \\text{R} \\\\\n",
    "G(x, y) & \\text{if } C(x, y) = \\text{G} \\\\\n",
    "B(x, y) & \\text{if } C(x, y) = \\text{B}\n",
    "\\end{cases}$$\n",
    "\n",
    "where $C(x, y)$ is the CFA pattern function.\n",
    "\n",
    "For Bayer RGGB pattern:\n",
    "\n",
    "$$C(x, y) = \\begin{cases}\n",
    "\\text{R} & \\text{if } x \\bmod 2 = 0 \\text{ and } y \\bmod 2 = 0 \\\\\n",
    "\\text{G} & \\text{if } x \\bmod 2 \\neq y \\bmod 2 \\\\\n",
    "\\text{B} & \\text{if } x \\bmod 2 = 1 \\text{ and } y \\bmod 2 = 1\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "### 1.2 X-Trans\n",
    "\n",
    "The application also supports the X-Trans pattern (Fujifilm, 2012), which uses a 6×6 aperiodic pattern instead of the 2×2 periodic Bayer pattern. The X-Trans pattern is defined by a lookup table for the 6×6 base unit:\n",
    "\n",
    "```\n",
    "G R G G B G\n",
    "B G B R G R\n",
    "G R G G B G\n",
    "G B G G R G\n",
    "R G R B G B\n",
    "G B G G R G\n",
    "```\n",
    "\n",
    "The pattern function $C(x, y)$ for X-Trans is:\n",
    "\n",
    "$$C(x, y) = \\text{XTransTable}[x \\bmod 6, y \\bmod 6]$$\n",
    "\n",
    "where `XTransTable` is the 6×6 lookup table above. Unlike Bayer's simple modulo formula, X-Trans requires a lookup table because the pattern is aperiodic and designed to reduce moiré artifacts by breaking the 2×2 periodicity.\n",
    "\n",
    "The implementation can be found in `simulateCFA()` in `cfa.ts` lines 34-61:\n",
    "```typescript\n",
    "export const simulateCFA = (\n",
    "  imageData: ImageData, \n",
    "  type: CFAType, \n",
    "  layout: string = 'RGGB'\n",
    "): Float32Array => {\n",
    "  const { width, height, data } = imageData;\n",
    "  const cfa = new Float32Array(width * height);\n",
    "  \n",
    "  let getChannel: (x: number, y: number) => 'r' | 'g' | 'b';\n",
    "  \n",
    "  if (type === 'bayer') {\n",
    "    getChannel = getBayerKernel(layout);\n",
    "  } else if (type === 'xtrans') {\n",
    "    getChannel = getXTransKernel();\n",
    "  }\n",
    "  \n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const ch = getChannel(x, y);\n",
    "      const idx = (y * width + x) * 4;\n",
    "      // Normalize 0-255 to 0-1\n",
    "      const val = ch === 'r' ? data[idx] : ch === 'g' ? data[idx + 1] : data[idx + 2];\n",
    "      cfa[y * width + x] = val / 255.0;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return cfa;\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eecbd31",
   "metadata": {},
   "source": [
    "## 2. Demosaicing Algorithms\n",
    "\n",
    "All algorithms use a unified expanding search approach that works for **any** CFA pattern. For each pixel, missing channels are interpolated by expanding the search radius until neighbors of the target color are found (up to a maximum radius, typically 10 pixels). This makes the algorithms pattern-agnostic and capable of handling any regular or irregular CFA arrangement.\n",
    "\n",
    "### 2.1 Bilinear Interpolation\n",
    "\n",
    "Bilinear interpolation interpolates missing channels by averaging available samples in local neighborhoods (Malvar et al., 2004). For any CFA pattern, the algorithm works as follows:\n",
    "\n",
    "For missing channel $c$ at position $(x, y)$:\n",
    "\n",
    "$$\\hat{I}_c(x, y) = \\frac{1}{|\\mathcal{N}_c(x,y)|} \\sum_{(x', y') \\in \\mathcal{N}_c(x,y)} M(x', y')$$\n",
    "\n",
    "where $\\mathcal{N}_c(x, y) = \\{(x', y') : C(x', y') = c \\text{ and } \\|(x-x', y-y')\\|_\\infty \\leq d_{\\max}\\}$ is the set of neighboring pixels of color $c$ found by expanding the search radius up to $d_{\\max}$ (typically 10 pixels). The expanding search automatically adapts to find neighbors regardless of the CFA pattern structure.\n",
    "\n",
    "The algorithm:\n",
    "1. For each pixel $(x, y)$ with sampled channel $C(x, y) = c_0$:\n",
    "   - Set $\\hat{I}_{c_0}(x, y) = M(x, y)$ (direct sample)\n",
    "   - For each missing channel $c \\neq c_0$:\n",
    "     - Expand search radius $d$ from 1 to $d_{\\max}$ (typically 10)\n",
    "     - Collect all neighbors $(x', y')$ where $C(x', y') = c$ and $\\|(x-x', y-y')\\|_\\infty \\leq d_{\\max}$\n",
    "     - Compute average: $\\hat{I}_c(x, y) = \\frac{1}{|\\mathcal{N}_c(x,y)|} \\sum_{(x', y') \\in \\mathcal{N}_c(x,y)} M(x', y')$\n",
    "\n",
    "The expanding search ensures that the algorithm works for any CFA pattern, not just Bayer or X-Trans. For regular patterns like Bayer, the search typically finds neighbors at distance $d=1$ or $d=\\sqrt{2}$. For irregular patterns, it automatically adapts to find the nearest available neighbors.\n",
    "\n",
    "Implementation (`demosaic.ts` lines 225-299):\n",
    "\n",
    "```typescript\n",
    "export const demosaicBilinear = (input: DemosaicInput): ImageData => {\n",
    "  const { width, height, cfaData } = input;\n",
    "  const output = new ImageData(width, height);\n",
    "  const getChannel = getChannelFunction(input);\n",
    "  \n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const centerVal = cfaData[y * width + x];\n",
    "      const centerCh = getChannel(x, y);\n",
    "      const idx = (y * width + x) * 4;\n",
    "      \n",
    "      let r = 0, g = 0, b = 0;\n",
    "\n",
    "      if (centerCh === 'g') {\n",
    "        g = centerVal;\n",
    "        \n",
    "        // Collect neighbors with expanding search (works for any CFA)\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        r = rNeighbors.values.length > 0 \n",
    "          ? rNeighbors.values.reduce((a, b) => a + b, 0) / rNeighbors.values.length \n",
    "          : 0;\n",
    "        b = bNeighbors.values.length > 0 \n",
    "          ? bNeighbors.values.reduce((a, b) => a + b, 0) / bNeighbors.values.length \n",
    "          : 0;\n",
    "      } else if (centerCh === 'r') {\n",
    "        r = centerVal;\n",
    "        \n",
    "        // Collect neighbors with expanding search\n",
    "        const gNeighbors = collectNeighbors(cfaData, width, height, x, y, 'g', getChannel);\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        g = gNeighbors.values.length > 0 \n",
    "          ? gNeighbors.values.reduce((a, b) => a + b, 0) / gNeighbors.values.length \n",
    "          : 0;\n",
    "        b = bNeighbors.values.length > 0 \n",
    "          ? bNeighbors.values.reduce((a, b) => a + b, 0) / bNeighbors.values.length \n",
    "          : 0;\n",
    "      } else if (centerCh === 'b') {\n",
    "        b = centerVal;\n",
    "        \n",
    "        // Collect neighbors with expanding search\n",
    "        const gNeighbors = collectNeighbors(cfaData, width, height, x, y, 'g', getChannel);\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        g = gNeighbors.values.length > 0 \n",
    "          ? gNeighbors.values.reduce((a, b) => a + b, 0) / gNeighbors.values.length \n",
    "          : 0;\n",
    "        r = rNeighbors.values.length > 0 \n",
    "          ? rNeighbors.values.reduce((a, b) => a + b, 0) / rNeighbors.values.length \n",
    "          : 0;\n",
    "      }\n",
    "      \n",
    "      output.data[idx] = clamp(r);\n",
    "      output.data[idx+1] = clamp(g);\n",
    "      output.data[idx+2] = clamp(b);\n",
    "      output.data[idx+3] = 255;\n",
    "    }\n",
    "  }\n",
    "  return output;\n",
    "};\n",
    "```\n",
    "\n",
    "The `collectNeighbors` helper function (lines 35-64 in `demosaic.ts`) collects all neighbors of the target color within a maximum search radius (default 10 pixels), making the algorithm work for any CFA pattern. It searches all pixels within the radius and collects those matching the target color channel.\n",
    "\n",
    "### 2.2 Niu Edge Sensing (Niu et al., 2018)\n",
    "\n",
    "The Niu algorithm interpolates missing channels by averaging all neighbors of the target color found using expanding search. The algorithm works for any CFA pattern.\n",
    "\n",
    "The algorithm:\n",
    "1. First pass: Interpolates green channel by collecting all green neighbors within the search radius and averaging\n",
    "2. Second pass: Interpolates R/B channels by collecting all neighbors of the target color within the search radius and averaging\n",
    "\n",
    "For all channels, the algorithm uses expanding search up to a maximum radius (typically 10 pixels) to find neighbors, ensuring it works for any CFA pattern.\n",
    "\n",
    "Implementation (`demosaic.ts` lines 326-400):\n",
    "\n",
    "```typescript\n",
    "export const demosaicNiuEdgeSensing = (input: DemosaicInput, params?: DemosaicParams): ImageData => {\n",
    "  const { width, height, cfaData } = input;\n",
    "  const output = new ImageData(width, height);\n",
    "  const getChannel = getChannelFunction(input);\n",
    "  \n",
    "  // First pass: Interpolate green channel\n",
    "  const greenInterp = new Float32Array(width * height);\n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const centerCh = getChannel(x, y);\n",
    "      const centerVal = cfaData[y * width + x];\n",
    "      \n",
    "      if (centerCh === 'g') {\n",
    "        greenInterp[y * width + x] = centerVal;\n",
    "      } else {\n",
    "        // Interpolate green at R/B pixel using expanding search\n",
    "        const gNeighbors = collectNeighbors(cfaData, width, height, x, y, 'g', getChannel);\n",
    "        greenInterp[y * width + x] = gNeighbors.values.length > 0 \n",
    "          ? gNeighbors.values.reduce((a, b) => a + b, 0) / gNeighbors.values.length \n",
    "          : centerVal;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Second pass: Interpolate R/B channels\n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const centerCh = getChannel(x, y);\n",
    "      const centerVal = cfaData[y * width + x];\n",
    "      const idx = (y * width + x) * 4;\n",
    "      \n",
    "      let r = 0, g = 0, b = 0;\n",
    "      \n",
    "      if (centerCh === 'r') {\n",
    "        r = centerVal;\n",
    "        g = greenInterp[y * width + x];\n",
    "        \n",
    "        // Average all blue neighbors with expanding search\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        b = bNeighbors.values.length > 0 \n",
    "          ? bNeighbors.values.reduce((a, b) => a + b, 0) / bNeighbors.values.length \n",
    "          : g;\n",
    "      } else if (centerCh === 'b') {\n",
    "        b = centerVal;\n",
    "        g = greenInterp[y * width + x];\n",
    "        \n",
    "        // Average all red neighbors with expanding search\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        r = rNeighbors.values.length > 0 \n",
    "          ? rNeighbors.values.reduce((a, b) => a + b, 0) / rNeighbors.values.length \n",
    "          : g;\n",
    "      } else {\n",
    "        // Green pixel\n",
    "        g = centerVal;\n",
    "        \n",
    "        // Average all neighbors with expanding search\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        r = rNeighbors.values.length > 0 \n",
    "          ? rNeighbors.values.reduce((a, b) => a + b, 0) / rNeighbors.values.length \n",
    "          : 0;\n",
    "        b = bNeighbors.values.length > 0 \n",
    "          ? bNeighbors.values.reduce((a, b) => a + b, 0) / bNeighbors.values.length \n",
    "          : 0;\n",
    "      }\n",
    "      \n",
    "      output.data[idx] = clamp(r);\n",
    "      output.data[idx + 1] = clamp(g);\n",
    "      output.data[idx + 2] = clamp(b);\n",
    "      output.data[idx + 3] = 255;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return output;\n",
    "};\n",
    "```\n",
    "\n",
    "### 2.3 Lien Edge-Based (Lien et al., 2017)\n",
    "\n",
    "The Lien algorithm detects edge direction by comparing horizontal and vertical color differences, then interpolates perpendicular to the detected edge direction.\n",
    "\n",
    "For green interpolation at R/B pixels:\n",
    "- Compute $\\Delta_H = |I(x-1,y) - I(x+1,y)|$ and $\\Delta_V = |I(x,y-1) - I(x,y+1)|$\n",
    "- If $\\Delta_H < \\Delta_V$ (horizontal edge), interpolate vertically: $\\hat{G} = \\frac{G(x,y-1) + G(x,y+1)}{2}$\n",
    "- Otherwise (vertical edge), interpolate horizontally: $\\hat{G} = \\frac{G(x-1,y) + G(x+1,y)}{2}$\n",
    "\n",
    "For R/B channels, it uses color difference interpolation similar to Niu.\n",
    "\n",
    "Implementation (`demosaic.ts` lines 500-575):\n",
    "\n",
    "```typescript\n",
    "export const demosaicLienEdgeBased = (input: DemosaicInput): ImageData => {\n",
    "  const { width, height, cfaData } = input;\n",
    "  const output = new ImageData(width, height);\n",
    "  const getChannel = getChannelFunction(input);\n",
    "  \n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const centerCh = getChannel(x, y);\n",
    "      const centerVal = cfaData[y * width + x];\n",
    "      const idx = (y * width + x) * 4;\n",
    "      \n",
    "      let r = 0, g = 0, b = 0;\n",
    "      \n",
    "      if (centerCh === 'g') {\n",
    "        g = centerVal;\n",
    "        \n",
    "        // Average all neighbors with expanding search\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        r = rNeighbors.values.length > 0 \n",
    "          ? rNeighbors.values.reduce((a, b) => a + b, 0) / rNeighbors.values.length \n",
    "          : 0;\n",
    "        b = bNeighbors.values.length > 0 \n",
    "          ? bNeighbors.values.reduce((a, b) => a + b, 0) / bNeighbors.values.length \n",
    "          : 0;\n",
    "      } else if (centerCh === 'r') {\n",
    "        r = centerVal;\n",
    "        \n",
    "        // Interpolate green using expanding search\n",
    "        const gNeighbors = collectNeighbors(cfaData, width, height, x, y, 'g', getChannel);\n",
    "        g = gNeighbors.values.length > 0 \n",
    "          ? gNeighbors.values.reduce((a, b) => a + b, 0) / gNeighbors.values.length \n",
    "          : 0;\n",
    "        \n",
    "        // Interpolate blue using expanding search\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        b = bNeighbors.values.length > 0 \n",
    "          ? bNeighbors.values.reduce((a, b) => a + b, 0) / bNeighbors.values.length \n",
    "          : g;\n",
    "      } else {\n",
    "        // Blue pixel\n",
    "        b = centerVal;\n",
    "        \n",
    "        // Interpolate green using expanding search\n",
    "        const gNeighbors = collectNeighbors(cfaData, width, height, x, y, 'g', getChannel);\n",
    "        g = gNeighbors.values.length > 0 \n",
    "          ? gNeighbors.values.reduce((a, b) => a + b, 0) / gNeighbors.values.length \n",
    "          : 0;\n",
    "        \n",
    "        // Interpolate red using expanding search\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        r = rNeighbors.values.length > 0 \n",
    "          ? rNeighbors.values.reduce((a, b) => a + b, 0) / rNeighbors.values.length \n",
    "          : g;\n",
    "      }\n",
    "      \n",
    "      output.data[idx] = clamp(r);\n",
    "      output.data[idx + 1] = clamp(g);\n",
    "      output.data[idx + 2] = clamp(b);\n",
    "      output.data[idx + 3] = 255;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return output;\n",
    "};\n",
    "```\n",
    "\n",
    "### 2.4 Wu Polynomial Interpolation (Wu et al., 2016)\n",
    "\n",
    "The Wu algorithm uses polynomial interpolation with distance-weighted averaging. It fits a polynomial of degree $d$ to neighboring samples, weighting by inverse distance squared: $w_i = \\frac{1}{1 + d_i^2}$.\n",
    "\n",
    "For green interpolation:\n",
    "$$\\hat{G}(x, y) = \\frac{\\sum_i G_i \\cdot w_i}{\\sum_i w_i}$$\n",
    "\n",
    "where $w_i = \\frac{1}{1 + d_i^2}$ and $d_i$ is the distance to neighbor $i$.\n",
    "\n",
    "For R/B channels, the algorithm uses color difference interpolation: $\\hat{B} = \\hat{G} + \\text{avg}(B - G)$ at neighboring locations.\n",
    "\n",
    "Implementation (`demosaic.ts` lines 577-700):\n",
    "\n",
    "```typescript\n",
    "export const demosaicWuPolynomial = (input: DemosaicInput, params?: DemosaicParams): ImageData => {\n",
    "  const { width, height, cfaData } = input;\n",
    "  const output = new ImageData(width, height);\n",
    "  const getChannel = getChannelFunction(input);\n",
    "  const degree = params?.wuPolynomialDegree ?? 2;\n",
    "  \n",
    "  // First pass: Interpolate green channel\n",
    "  const greenInterp = new Float32Array(width * height);\n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const centerCh = getChannel(x, y);\n",
    "      const centerVal = cfaData[y * width + x];\n",
    "      \n",
    "      if (centerCh === 'g') {\n",
    "        greenInterp[y * width + x] = centerVal;\n",
    "      } else {\n",
    "        // Use polynomial interpolation for green - expanding search\n",
    "        const gNeighbors = collectNeighbors(cfaData, width, height, x, y, 'g', getChannel);\n",
    "        if (gNeighbors.values.length > 0) {\n",
    "          greenInterp[y * width + x] = polynomialInterpolate(gNeighbors.values, gNeighbors.distances, degree);\n",
    "        } else {\n",
    "          greenInterp[y * width + x] = centerVal;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Second pass: Interpolate R/B using polynomial interpolation\n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const centerCh = getChannel(x, y);\n",
    "      const centerVal = cfaData[y * width + x];\n",
    "      const idx = (y * width + x) * 4;\n",
    "      \n",
    "      let r = 0, g = 0, b = 0;\n",
    "      \n",
    "      if (centerCh === 'r') {\n",
    "        r = centerVal;\n",
    "        g = greenInterp[y * width + x];\n",
    "        \n",
    "        // Use polynomial interpolation on all blue neighbors\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        if (bNeighbors.values.length > 0) {\n",
    "          b = polynomialInterpolate(bNeighbors.values, bNeighbors.distances, degree);\n",
    "        } else {\n",
    "          b = g;\n",
    "        }\n",
    "      } else if (centerCh === 'b') {\n",
    "        b = centerVal;\n",
    "        g = greenInterp[y * width + x];\n",
    "        \n",
    "        // Use polynomial interpolation on all red neighbors\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        if (rNeighbors.values.length > 0) {\n",
    "          r = polynomialInterpolate(rNeighbors.values, rNeighbors.distances, degree);\n",
    "        } else {\n",
    "          r = g;\n",
    "        }\n",
    "      } else {\n",
    "        // Green pixel\n",
    "        g = centerVal;\n",
    "        \n",
    "        // Use polynomial interpolation on all neighbors\n",
    "        const rNeighbors = collectNeighbors(cfaData, width, height, x, y, 'r', getChannel);\n",
    "        const bNeighbors = collectNeighbors(cfaData, width, height, x, y, 'b', getChannel);\n",
    "        if (rNeighbors.values.length > 0) {\n",
    "          r = polynomialInterpolate(rNeighbors.values, rNeighbors.distances, degree);\n",
    "        }\n",
    "        if (bNeighbors.values.length > 0) {\n",
    "          b = polynomialInterpolate(bNeighbors.values, bNeighbors.distances, degree);\n",
    "        }\n",
    "      }\n",
    "      \n",
    "      output.data[idx] = clamp(r);\n",
    "      output.data[idx + 1] = clamp(g);\n",
    "      output.data[idx + 2] = clamp(b);\n",
    "      output.data[idx + 3] = 255;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return output;\n",
    "};\n",
    "```\n",
    "\n",
    "### 2.5 Kiku Residual Interpolation (Kiku et al., 2016)\n",
    "\n",
    "The Kiku algorithm performs iterative residual interpolation. It starts with a bilinear estimate, then iteratively refines by:\n",
    "1. Computing residual at sampled locations: $R^{(k)}(x_s, y_s) = M(x_s, y_s) - \\hat{I}^{(k)}(x_s, y_s)$\n",
    "2. Interpolating the residual: $\\hat{R}^{(k)} = \\text{Interp}(R^{(k)})$\n",
    "3. Updating estimate: $\\hat{I}^{(k+1)} = \\hat{I}^{(k)} + \\hat{R}^{(k)}$\n",
    "\n",
    "This process converges geometrically, reducing error by approximately half each iteration up to the fundamental limit of bilinear interpolation.\n",
    "\n",
    "Implementation (`demosaic.ts` lines 545-680):\n",
    "\n",
    "```typescript\n",
    "export const demosaicKikuResidual = (input: DemosaicInput, params?: DemosaicParams): ImageData => {\n",
    "  const { width, height, cfaData } = input;\n",
    "  const iterations = params?.kikuResidualIterations ?? 1;\n",
    "  const getChannel = getChannelFunction(input);\n",
    "  \n",
    "  // Initial estimation using bilinear interpolation\n",
    "  const initial = demosaicBilinear(input);\n",
    "  \n",
    "  // Convert initial estimate to Float32Array for processing\n",
    "  const initialR = new Float32Array(width * height);\n",
    "  const initialG = new Float32Array(width * height);\n",
    "  const initialB = new Float32Array(width * height);\n",
    "  \n",
    "  for (let i = 0; i < width * height; i++) {\n",
    "    initialR[i] = initial.data[i * 4] / 255.0;\n",
    "    initialG[i] = initial.data[i * 4 + 1] / 255.0;\n",
    "    initialB[i] = initial.data[i * 4 + 2] / 255.0;\n",
    "  }\n",
    "  \n",
    "  // Refine estimates: initial + interpolated residuals (with iterations)\n",
    "  const residualR = new Float32Array(width * height);\n",
    "  const residualG = new Float32Array(width * height);\n",
    "  const residualB = new Float32Array(width * height);\n",
    "  const interpolatedResidualR = new Float32Array(width * height);\n",
    "  const interpolatedResidualG = new Float32Array(width * height);\n",
    "  const interpolatedResidualB = new Float32Array(width * height);\n",
    "  let currentR = new Float32Array(initialR);\n",
    "  let currentG = new Float32Array(initialG);\n",
    "  let currentB = new Float32Array(initialB);\n",
    "  \n",
    "  for (let iter = 0; iter < iterations; iter++) {\n",
    "    // Compute residuals from current estimate\n",
    "    for (let y = 0; y < height; y++) {\n",
    "      for (let x = 0; x < width; x++) {\n",
    "        const centerCh = getChannel(x, y);\n",
    "        const centerVal = cfaData[y * width + x];\n",
    "        const idx = y * width + x;\n",
    "        \n",
    "        if (centerCh === 'r') {\n",
    "          residualR[idx] = centerVal - currentR[idx];\n",
    "          residualG[idx] = 0;\n",
    "          residualB[idx] = 0;\n",
    "        } else if (centerCh === 'g') {\n",
    "          residualR[idx] = 0;\n",
    "          residualG[idx] = centerVal - currentG[idx];\n",
    "          residualB[idx] = 0;\n",
    "        } else {\n",
    "          residualR[idx] = 0;\n",
    "          residualG[idx] = 0;\n",
    "          residualB[idx] = centerVal - currentB[idx];\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    // Interpolate residuals (reuse the same interpolation logic)\n",
    "    for (let y = 0; y < height; y++) {\n",
    "      for (let x = 0; x < width; x++) {\n",
    "        const centerCh = getChannel(x, y);\n",
    "        const idx = y * width + x;\n",
    "        \n",
    "        if (centerCh === 'r') {\n",
    "          interpolatedResidualR[idx] = residualR[idx];\n",
    "          \n",
    "          // Average all neighbors with expanding search\n",
    "          const gVals = collectResidualNeighbors(residualG, width, height, x, y, 'g', getChannel);\n",
    "          const bVals = collectResidualNeighbors(residualB, width, height, x, y, 'b', getChannel);\n",
    "          interpolatedResidualG[idx] = gVals.length > 0 ? gVals.reduce((a, b) => a + b, 0) / gVals.length : 0;\n",
    "          interpolatedResidualB[idx] = bVals.length > 0 ? bVals.reduce((a, b) => a + b, 0) / bVals.length : 0;\n",
    "        } else if (centerCh === 'g') {\n",
    "          interpolatedResidualG[idx] = residualG[idx];\n",
    "          \n",
    "          // Average all neighbors with expanding search\n",
    "          const rVals = collectResidualNeighbors(residualR, width, height, x, y, 'r', getChannel);\n",
    "          const bVals = collectResidualNeighbors(residualB, width, height, x, y, 'b', getChannel);\n",
    "          interpolatedResidualR[idx] = rVals.length > 0 ? rVals.reduce((a, b) => a + b, 0) / rVals.length : 0;\n",
    "          interpolatedResidualB[idx] = bVals.length > 0 ? bVals.reduce((a, b) => a + b, 0) / bVals.length : 0;\n",
    "        } else {\n",
    "          interpolatedResidualB[idx] = residualB[idx];\n",
    "          \n",
    "          // Average all neighbors with expanding search\n",
    "          const gVals = collectResidualNeighbors(residualG, width, height, x, y, 'g', getChannel);\n",
    "          const rVals = collectResidualNeighbors(residualR, width, height, x, y, 'r', getChannel);\n",
    "          interpolatedResidualG[idx] = gVals.length > 0 ? gVals.reduce((a, b) => a + b, 0) / gVals.length : 0;\n",
    "          interpolatedResidualR[idx] = rVals.length > 0 ? rVals.reduce((a, b) => a + b, 0) / rVals.length : 0;\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    // Update current estimate\n",
    "    for (let i = 0; i < width * height; i++) {\n",
    "      currentR[i] += interpolatedResidualR[i];\n",
    "      currentG[i] += interpolatedResidualG[i];\n",
    "      currentB[i] += interpolatedResidualB[i];\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Final output\n",
    "  const output = new ImageData(width, height);\n",
    "  for (let y = 0; y < height; y++) {\n",
    "    for (let x = 0; x < width; x++) {\n",
    "      const idx = y * width + x;\n",
    "      const outIdx = (y * width + x) * 4;\n",
    "      \n",
    "      output.data[outIdx] = clamp(currentR[idx]);\n",
    "      output.data[outIdx + 1] = clamp(currentG[idx]);\n",
    "      output.data[outIdx + 2] = clamp(currentB[idx]);\n",
    "      output.data[outIdx + 3] = 255;\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return output;\n",
    "};\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bilinear",
   "metadata": {},
   "source": [
    "## 3. Error Analysis\n",
    "\n",
    "### 3.1 Error Metrics\n",
    "\n",
    "#### 3.1.1 Mean Squared Error (MSE)\n",
    "\n",
    "MSE is defined as:\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{3WH} \\sum_{c \\in \\{R,G,B\\}} \\sum_{x=0}^{W-1} \\sum_{y=0}^{H-1} (I_c(x,y) - \\hat{I}_c(x,y))^2$$\n",
    "\n",
    "Per-channel MSE:\n",
    "\n",
    "$$\\text{MSE}_c = \\frac{1}{WH} \\sum_{x,y} (I_c(x,y) - \\hat{I}_c(x,y))^2 = \\mathbb{E}[(I_c - \\hat{I}_c)^2]$$\n",
    "\n",
    "MSE is used because it's the $L_2$ norm squared, which:\n",
    "1. Has clean mathematical properties (differentiable, convex)\n",
    "2. Penalizes large errors more than small ones (due to squaring)\n",
    "3. Relates to signal power and SNR in signal processing theory\n",
    "\n",
    "The implementation can be found in `computeErrorStats()` in `demosaic.ts` lines 309-409.\n",
    "\n",
    "#### 3.1.2 Peak Signal-to-Noise Ratio (PSNR)\n",
    "\n",
    "PSNR is defined as (Gunturk et al., 2005):\n",
    "\n",
    "$$\\text{PSNR} = 10 \\log_{10}\\left(\\frac{\\text{MAX}^2}{\\text{MSE}}\\right) = 20 \\log_{10}\\left(\\frac{\\text{MAX}}{\\sqrt{\\text{MSE}}}\\right)$$\n",
    "\n",
    "For 8-bit images, $\\text{MAX} = 255$:\n",
    "\n",
    "$$\\text{PSNR} = 20 \\log_{10}(255) - 10\\log_{10}(\\text{MSE}) \\approx 48.13 - 10\\log_{10}(\\text{MSE})$$\n",
    "\n",
    "PSNR can be interpreted as:\n",
    "\n",
    "$$\\text{PSNR}(\\text{dB}) = \\begin{cases}\n",
    "> 40 & \\text{Excellent - artifacts barely visible} \\\\\n",
    "30-40 & \\text{Good - minor artifacts} \\\\\n",
    "20-30 & \\text{Fair - noticeable artifacts} \\\\\n",
    "< 20 & \\text{Poor - severe artifacts}\n",
    "\\end{cases}$$\n",
    "\n",
    "Why logarithmic? Human perception of image quality is approximately logarithmic with respect to error power (Gunturk et al., 2005). A 10 dB difference roughly corresponds to a perceivable quality difference.\n",
    "\n",
    "#### 3.1.3 Structural Similarity Index (SSIM)\n",
    "\n",
    "MSE and PSNR treat all errors equally, but human vision is sensitive to structural information (patterns, edges, textures) more than absolute pixel values (Wang et al., 2004). For two image patches $\\mathbf{x}$ and $\\mathbf{y}$, SSIM is defined as (Wang et al., 2004):\n",
    "\n",
    "$$\\text{SSIM}(\\mathbf{x}, \\mathbf{y}) = \\frac{(2\\mu_x\\mu_y + C_1)(2\\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}$$\n",
    "\n",
    "where:\n",
    "- $\\mu_x = \\frac{1}{N}\\sum_{i=1}^N x_i$ (mean)\n",
    "- $\\sigma_x^2 = \\frac{1}{N-1}\\sum_{i=1}^N (x_i - \\mu_x)^2$ (variance)\n",
    "- $\\sigma_{xy} = \\frac{1}{N-1}\\sum_{i=1}^N (x_i - \\mu_x)(y_i - \\mu_y)$ (covariance)\n",
    "- $C_1 = (0.01 \\times 255)^2$, $C_2 = (0.03 \\times 255)^2$ (stability constants)\n",
    "\n",
    "SSIM measures three components:\n",
    "\n",
    "1. Luminance comparison: $l(\\mathbf{x}, \\mathbf{y}) = \\frac{2\\mu_x\\mu_y + C_1}{\\mu_x^2 + \\mu_y^2 + C_1}$\n",
    "2. Contrast comparison: $c(\\mathbf{x}, \\mathbf{y}) = \\frac{2\\sigma_x\\sigma_y + C_2}{\\sigma_x^2 + \\sigma_y^2 + C_2}$\n",
    "3. Structure comparison: $s(\\mathbf{x}, \\mathbf{y}) = \\frac{\\sigma_{xy} + C_2/2}{\\sigma_x\\sigma_y + C_2/2}$\n",
    "\n",
    "Then: $\\text{SSIM} = l(\\mathbf{x}, \\mathbf{y}) \\cdot c(\\mathbf{x}, \\mathbf{y}) \\cdot s(\\mathbf{x}, \\mathbf{y})$\n",
    "\n",
    "SSIM has the following properties (Wang et al., 2004):\n",
    "- $\\text{SSIM} \\in [-1, 1]$, where 1 means perfect structural similarity\n",
    "- Symmetric: $\\text{SSIM}(\\mathbf{x}, \\mathbf{y}) = \\text{SSIM}(\\mathbf{y}, \\mathbf{x})$\n",
    "- More robust to uniform brightness/contrast shifts than MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfada067",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Bilinear Interpolation Error Analysis\n",
    "\n",
    "In this section we analyze the reconstruction error of bilinear interpolation given CFA samples, i.e.\n",
    "\n",
    "$$e_c(x,y) := I^{\\text{CFA}}_c(x,y) - \\hat I_c(x,y),$$\n",
    "\n",
    "where $I^{\\text{CFA}}_c$ is the (subsampled) channel value implied by the CFA at $(x,y)$ and $\\hat I_c$ is the value reconstructed by the algorithm. We do not model the aliasing error introduced by the CFA sampling itself; all bounds here are conditional on the CFA samples and characterize only the interpolation component of the error.\n",
    "\n",
    "We assume each color channel $I_c(x,y)$ is sufficiently smooth and satisfies\n",
    "\n",
    "$$|\\nabla I_c|_\\infty \\le L,\\qquad |H I_c|_\\infty \\le M,$$\n",
    "\n",
    "where $H I_c$ is the Hessian (matrix of second derivatives) and the norms are taken over the image domain. Intuitively, $L$ bounds local gradients and $M$ bounds local curvature.\n",
    "\n",
    "#### 3.2.1 Provable Worst-Case Bounds\n",
    "\n",
    "Because bilinear interpolation is a convex combination of neighbor samples, the reconstructed value lies between the minimum and maximum input values. For 8-bit images with values in $[0,255]$:\n",
    "\n",
    "$$|I_c(x,y) - \\hat I_c(x,y)| \\le 255.$$\n",
    "\n",
    "At each Bayer pixel, one color channel is directly sampled (zero reconstruction error) and two are interpolated. Thus, per pixel:\n",
    "\n",
    "* L1 total error\n",
    "\n",
    "  $$|R_{\\text{err}}| + |G_{\\text{err}}| + |B_{\\text{err}}| \\le 2\\cdot 255 = 510.$$\n",
    "\n",
    "* L2 total error\n",
    "\n",
    "  $$\\sqrt{R_{\\text{err}}^2 + G_{\\text{err}}^2 + B_{\\text{err}}^2} \\le 255\\sqrt{2} \\approx 360.$$\n",
    "\n",
    "Relating this to PSNR, for a single channel:\n",
    "\n",
    "$$PSNR = 10\\log_{10}\\frac{255^2}{MSE} = 20\\log_{10}\\frac{255}{RMSE}.$$\n",
    "\n",
    "If the error is 255 at every pixel, then $MSE=255^2$ and $PSNR = 0$ dB. This is the absolute worst possible case and is independent of the interpolation algorithm.\n",
    "\n",
    "These bounds are provable and sharp but essentially trivial; they give no insight into how interpolation behaves on typical smooth natural images.\n",
    "\n",
    "#### 3.2.2 Average Bounds (Smooth Images via Taylor Expansion)\n",
    "\n",
    "For smooth images, we can derive more informative curvature-based bounds. Consider a point $(x,y)$ and a nearby point $(x',y')$ at distance $d = |(x'-x, y'-y)|$. Taylor expansion gives\n",
    "\n",
    "$$I_c(x', y') = I_c(x, y) + \\nabla I_c(x, y)^\\top (x'-x, y'-y) + \\frac{1}{2}(x'-x, y'-y)^\\top H (x'-x, y'-y) + O(d^3).$$\n",
    "\n",
    "Bilinear interpolation on a regular grid:\n",
    "\n",
    "* Exactly reproduces constant and linear terms $(1, x, y)$,\n",
    "* Exactly reproduces the mixed term $xy$,\n",
    "* So the leading error comes from the pure second-derivative terms $I_{xx}$ and $I_{yy}$.\n",
    "\n",
    "If the maximum distance from an interpolated pixel to the neighbors used in bilinear interpolation is $d$, then, using $|H I_c|_\\infty \\le M$, we obtain a conservative bound of the form\n",
    "\n",
    "$$|I_c(x,y) - \\hat I_c(x,y)| \\le \\frac{M d^2}{2} \\equiv E.$$\n",
    "\n",
    "Assuming (pessimistically) this bound holds with equality at every pixel:\n",
    "\n",
    "$$MSE_c \\le E^2,\\qquad PSNR_c \\ge 20\\log_{10}\\frac{255}{E} = 20\\log_{10}\\left(\\frac{510}{M d^2}\\right).$$\n",
    "\n",
    "For a Bayer CFA, the farthest same-color neighbors used in simple bilinear demosaicing are typically at distance $d = \\sqrt{2}$, giving $d^2 = 2$ and\n",
    "\n",
    "$$E = \\frac{M \\cdot 2}{2} = M,\\qquad PSNR_c \\ge 20\\log_{10}\\left(\\frac{255}{M}\\right).$$\n",
    "\n",
    "Illustrative bounds (per channel):\n",
    "\n",
    "| Image Type     | Typical $M$ | Error Bound (Bayer, $d=\\sqrt{2}$) | $MSE_c \\le$ | $PSNR_c \\ge$ |\n",
    "| -------------- | ----------: | --------------------------------- | ----------: | -----------: |\n",
    "| Smooth sky     |          ~1 | ≤ 1                               |           1 |        48 dB |\n",
    "| Gentle texture |         ~10 | ≤ 10                              |         100 |        28 dB |\n",
    "| Moderate edges |         ~50 | ≤ 50                              |        2500 |        14 dB |\n",
    "| Sharp edges    |        ~200 | ≤ 200                             |       40000 |         2 dB |\n",
    "\n",
    "These PSNR values are lower bounds under a pessimistic assumption that every pixel attains the maximum local error. In real images, only some regions have large curvature, so actual PSNR is typically higher.\n",
    "\n",
    "These curvature-based bounds explain why bilinear works reasonably well on smooth regions (small $M$) but say nothing about aliasing or extreme patterns. For 8-bit images, the maximum possible discrete second derivative is on the order of 510 (e.g. checkerboard patterns), so for worst-case signals $M$ approaches this theoretical limit and the Taylor smoothness assumption itself breaks down. In that regime, the range-based bound $(|I_c - \\hat I_c|\\le 255)$ is the only meaningful guarantee.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e7b97",
   "metadata": {},
   "source": [
    "\n",
    "### 3.3 Niu Edge-Sensing Bound\n",
    "\n",
    "The Niu algorithm interpolates green using a weighted combination of directional estimates:\n",
    "\n",
    "$$\\hat G(x,y) = \\frac{\\sum_{i\\in\\{H,V,D1,D2\\}} w_i, G_i}{\\sum_i w_i},$$\n",
    "\n",
    "where each $G_i$ is a directional interpolation (horizontal, vertical, and two diagonals), and weights are\n",
    "\n",
    "$$w_i = 1 - \\frac{\\sigma(\\Delta_i)}{\\sum_j \\sigma(\\Delta_j)},\\qquad \\sigma(\\Delta) = \\frac{1}{1 + e^{-k(\\Delta - \\theta)}}.$$\n",
    "\n",
    "Each neighbor $G_i$ can be expanded as\n",
    "\n",
    "$$G_i = I_c(x,y) + \\nabla I_c(x,y)^\\top \\vec d_i + \\frac{1}{2}\\vec d_i^\\top H \\vec d_i + O(|\\vec d_i|^3),$$\n",
    "\n",
    "where $\\vec d_i$ is the offset from $(x,y)$ to the neighbor used for $G_i$. Substituting into the weighted average:\n",
    "\n",
    "$$\\hat G(x,y) = I_c(x,y) + \\frac{\\sum_i w_i, \\nabla I_c^\\top \\vec d_i}{\\sum_i w_i} + \\frac{\\sum_i w_i, \\frac{1}{2}\\vec d_i^\\top H \\vec d_i}{\\sum_i w_i} + O(d_{\\max}^3),$$\n",
    "\n",
    "with $d_{\\max} = \\max_i |\\vec d_i|$.\n",
    "\n",
    "Unlike symmetric bilinear interpolation, the weights $w_i$ are generally asymmetric, so the linear term does not cancel in general. Using $|\\nabla I_c|_\\infty \\le L$ and $|H I_c|_\\infty \\le M$, we obtain:\n",
    "\n",
    "* Linear term bound\n",
    "\n",
    "  $$\\left| \\frac{\\sum_i w_i, \\nabla I_c^\\top \\vec d_i}{\\sum_i w_i} \\right| \\le L, d_{\\max} ,\\max_i \\frac{w_i}{\\sum_j w_j}.$$\n",
    "\n",
    "* Quadratic term bound\n",
    "\n",
    "  $$\\left| \\frac{\\sum_i w_i, \\frac{1}{2}\\vec d_i^\\top H \\vec d_i}{\\sum_i w_i} \\right| \\le \\frac{M d_{\\max}^2}{2}.$$\n",
    "\n",
    "If edge detection correctly de-emphasizes across-edge directions, the largest normalized weight can be significantly less than 1. As a simple illustrative case for a Bayer CFA with $d_{\\max} = \\sqrt{2}$, suppose that good edge detection effectively halves the largest normalized weight, i.e.\n",
    "\n",
    "$$\\max_i \\frac{w_i}{\\sum_j w_j} \\approx 0.5.$$\n",
    "\n",
    "Then the reconstruction error magnitude is bounded by\n",
    "\n",
    "$$|e_c(x,y)| \\lesssim \\frac{M d_{\\max}^2}{2} + 0.5,L d_{\\max} = M + 0.5 L\\sqrt{2}.$$\n",
    "\n",
    "Assuming this bound everywhere gives\n",
    "\n",
    "$$MSE_c \\le \\bigl(M + 0.5 L\\sqrt{2}\\bigr)^2,\\qquad PSNR_c \\ge 20\\log_{10}\\frac{255}{M + 0.5 L\\sqrt{2}}.$$\n",
    "\n",
    "Example for a smooth sky with mild edges $(M\\approx 1, L\\approx 5)$:\n",
    "\n",
    "$$|e_c| \\lesssim 1 + 0.5\\cdot 5\\sqrt{2} \\approx 4.5,\\qquad PSNR_c \\gtrsim 35,\\text{dB}.$$\n",
    "\n",
    "This bound is most informative when edges are well-detected and gradients are moderate. If edge detection fails (e.g. in textured or noisy regions), the asymmetric weights may amplify linear-gradient contributions, degrading performance toward or below bilinear levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a06a8",
   "metadata": {},
   "source": [
    "\n",
    "### 3.4 Lien Edge-Based Bound\n",
    "\n",
    "Lien's method detects edge orientation via local intensity differences:\n",
    "\n",
    "* Horizontal variation:\n",
    "\n",
    "  $$\\Delta_H = |I(x-1,y) - I(x+1,y)|$$\n",
    "\n",
    "* Vertical variation:\n",
    "\n",
    "  $$\\Delta_V = |I(x,y-1) - I(x,y+1)|.$$\n",
    "\n",
    "If $\\Delta_H < \\Delta_V$ (horizontal edge), it interpolates along the smoother vertical direction (distance $d=1$):\n",
    "\n",
    "$$\\hat C(x,y) = \\frac{C(x,y-1) + C(x,y+1)}{2}.$$\n",
    "\n",
    "With unit pixel spacing, a Taylor expansion in the vertical direction gives\n",
    "\n",
    "$$C(x,y\\pm 1) = C(x,y) \\pm C_y(x,y) + \\frac{1}{2}C_{yy}(x,y) + O(1),$$\n",
    "\n",
    "so the symmetric average yields\n",
    "\n",
    "$$\\hat C(x,y) = C(x,y) + \\frac{1}{2}C_{yy}(x,y) + O(1).$$\n",
    "\n",
    "The linear terms cancel, and the leading error is proportional to the second derivative. Using $|C_{yy}|\\le M$ and ignoring the higher-order remainder in a conservative way:\n",
    "\n",
    "* Correct classification (interpolating perpendicular to the edge, $d=1$):\n",
    "\n",
    "  $$|C(x,y) - \\hat C(x,y)| \\lesssim \\frac{M}{2}.$$\n",
    "\n",
    "If the edge is misclassified and interpolation is done along the edge using diagonally separated pixels at distance $d = \\sqrt{2}$, the curvature term scales like $d^2$, giving:\n",
    "\n",
    "* Misclassification / diagonal interpolation:\n",
    "\n",
    "  $$|C(x,y) - \\hat C(x,y)| \\lesssim \\frac{M d^2}{2} = M.$$\n",
    "\n",
    "For correct classification, assuming the error bound holds everywhere:\n",
    "\n",
    "$$MSE_c \\le \\left(\\frac{M}{2}\\right)^2 = \\frac{M^2}{4},\\qquad PSNR_c \\ge 20\\log_{10}\\frac{255}{M/2} = 20\\log_{10}\\frac{510}{M}.$$\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Smooth sky, $M\\approx 1$:  $E\\approx 0.5$,  $PSNR_c \\gtrsim 54$ dB.\n",
    "* Gentle texture, $M\\approx 10$: $E\\approx 5$,  $PSNR_c \\gtrsim 34$ dB.\n",
    "\n",
    "The bound shows that Lien can be significantly better than bilinear (which has error $(\\sim M)$) when edge direction is correctly identified and interpolation is performed along the smoother direction. In regions where directional estimates are unreliable (e.g. weak edges or ambiguous gradients), misclassification pushes the scheme back toward bilinear-like behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68f26c",
   "metadata": {},
   "source": [
    "\n",
    "### 3.5 Wu Polynomial Bound\n",
    "\n",
    "Wu's method uses distance-based weighting:\n",
    "\n",
    "$$w_i = \\frac{1}{1 + d_i^2},\\qquad \\hat C(x,y) = \\frac{\\sum_i w_i, C_i}{\\sum_i w_i},$$\n",
    "\n",
    "where $C_i$ is the value at neighbor $i$ and $d_i$ is its distance from $(x,y)$.\n",
    "\n",
    "Expanding each neighbor:\n",
    "\n",
    "$$C_i = C(x,y) + \\nabla C(x,y)^\\top \\vec d_i + \\frac{1}{2}\\vec d_i^\\top H \\vec d_i + O(|\\vec d_i|^3),$$\n",
    "\n",
    "we obtain\n",
    "\n",
    "$$\\hat C(x,y) = C(x,y) + \\frac{\\sum_i w_i, \\nabla C^\\top \\vec d_i}{\\sum_i w_i} + \\frac{\\sum_i w_i, \\frac{1}{2}\\vec d_i^\\top H \\vec d_i}{\\sum_i w_i} + O(d_{\\max}^3).$$\n",
    "\n",
    "For a Bayer pattern, a common case is using four diagonal neighbors at equal distance $d=\\sqrt{2}$. In that configuration:\n",
    "\n",
    "* All $w_i$ are equal $(w_i = 1/(1+d^2) = 1/3)$,\n",
    "* The diagonal offsets are symmetric and sum to zero,\n",
    "* Therefore $\\sum_i w_i \\vec d_i = 0$, and the linear term cancels exactly, as in bilinear.\n",
    "\n",
    "The leading error is again governed by curvature:\n",
    "\n",
    "$$\\left| \\frac{\\sum_i w_i, \\frac{1}{2}\\vec d_i^\\top H \\vec d_i}{\\sum_i w_i} \\right| \\le \\frac{M d_{\\max}^2}{2}.$$\n",
    "\n",
    "For $d_{\\max}=\\sqrt{2}$ this gives\n",
    "\n",
    "$$|C(x,y) - \\hat C(x,y)| \\lesssim \\frac{M\\cdot 2}{2} = M.$$\n",
    "\n",
    "Thus, under only the smoothness assumption $|H C|_\\infty \\le M$, Wu's scheme shares essentially the same worst-case reconstruction bound as bilinear in this configuration. The distance weighting improves empirical performance by downweighting farther (and often less reliable) neighbors, but it does not, by itself, tighten the uniform curvature-based error bound.\n",
    "\n",
    "Assuming the bound holds everywhere:\n",
    "\n",
    "$$MSE_c \\le M^2,\\qquad PSNR_c \\ge 20\\log_{10}\\frac{255}{M}.$$\n",
    "\n",
    "For $M=10$, this gives $PSNR_c \\gtrsim 28$ dB, matching the bilinear curvature bound.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1cc30a",
   "metadata": {},
   "source": [
    "\n",
    "### 3.6 Kiku Residual Bound\n",
    "\n",
    "Kiku's method applies iterative residual interpolation:\n",
    "\n",
    "1. Initial estimate via bilinear interpolation:\n",
    "\n",
    "   $$\\hat I^{(0)}.$$\n",
    "\n",
    "2. For iteration $k = 0,\\dots,K-1$:\n",
    "\n",
    "   * Compute residual at CFA-sampled pixels:\n",
    "\n",
    "     $$R^{(k)} = I^{\\text{CFA}} - \\hat I^{(k)}.$$\n",
    "\n",
    "   * Interpolate the residual:\n",
    "\n",
    "     $$\\hat R^{(k)} = \\text{Interp}(R^{(k)}).$$\n",
    "\n",
    "   * Update the estimate:\n",
    "\n",
    "     $$\\hat I^{(k+1)} = \\hat I^{(k)} + \\hat R^{(k)}.$$\n",
    "\n",
    "The first step has an error bounded by the bilinear curvature bound:\n",
    "\n",
    "$$|I^{\\text{CFA}} - \\hat I^{(0)}| \\lesssim \\frac{M d^2}{2}.$$\n",
    "\n",
    "If the residual $R^{(k)}$ becomes progressively smoother (smaller effective curvature) as $k$ increases, the same type of interpolation produces smaller and smaller errors. Empirically, this often behaves like geometric error decay:\n",
    "\n",
    "$$|e^{(k+1)}| \\approx \\alpha ,|e^{(k)}|,\\qquad 0 < \\alpha < 1,$$\n",
    "\n",
    "where $e^{(k)} = I^{\\text{CFA}} - \\hat I^{(k)}$ and $\\alpha$ depends on image statistics and the interpolation operator. For typical natural images, a value $\\alpha \\approx 0.6$ is plausible.\n",
    "\n",
    "After $K$ iterations,\n",
    "\n",
    "$$|e^{(K)}| \\approx \\alpha^K |e^{(0)}| \\lesssim \\alpha^K \\frac{M d^2}{2}.$$\n",
    "\n",
    "For a Bayer pattern with $d = \\sqrt{2}$ and $K=3$ iterations, taking $\\alpha \\approx 0.6$ yields\n",
    "\n",
    "$$|e_c(x,y)| \\lesssim 0.22M.$$\n",
    "\n",
    "Assuming this holds everywhere:\n",
    "\n",
    "$$MSE_c \\lesssim (0.22 M)^2,\\qquad PSNR_c \\gtrsim 20\\log_{10}\\frac{255}{0.22 M} = 20\\log_{10}\\frac{1159}{M}.$$\n",
    "\n",
    "For gentle texture with $M \\approx 10$:\n",
    "\n",
    "$$|e_c| \\lesssim 2.2,\\qquad PSNR_c \\gtrsim 41,\\text{dB}.$$\n",
    "\n",
    "Unlike previous bounds, this is explicitly empirical: it depends on the observed residual smoothness and is not a strict worst-case guarantee. Nevertheless, it captures the key idea that iterative residual interpolation can significantly reduce reconstruction error when the residual is smoother (less curved) than the original image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73b366",
   "metadata": {},
   "source": [
    "\n",
    "### 3.7 Comparison of Bounds\n",
    "\n",
    "For smooth images satisfying $|H I_c|_\\infty \\le M$ and $|\\nabla I_c|_\\infty \\le L$, the reconstruction error bounds derived above can be summarized (per channel) as follows.\n",
    "\n",
    "Using a representative case $(M = 10)$, $(L = 50)$:\n",
    "\n",
    "| Algorithm  | Error Bound (per channel) | Conditions | $PSNR_c$ ($M=10$, $L=50$) |\n",
    "| ---------- | ------------------------- | ---------- | ------------------------- |\n",
    "| Bilinear   | $\\|e_c\\| \\lesssim M$                  | Always                            | ≥ 28 dB    |\n",
    "| Niu        | $\\|e_c\\| \\lesssim M + 0.5 L\\sqrt{2}$  | Good edge detection, moderate $L$ | ≥ 15 dB    |\n",
    "| Lien       | $\\|e_c\\| \\lesssim \\frac{M}{2}$ to $M$ | Correct / incorrect direction     | ≈ 34–28 dB |\n",
    "| Wu         | $\\|e_c\\| \\lesssim M$                  | Symmetric neighbors               | ≥ 28 dB    |\n",
    "| Kiku (K=3) | $\\|e_c\\| \\lesssim 0.22M$              | Residual smooth, α≈0.6            | ≳ 41 dB    |\n",
    "\n",
    "Key takeaways:\n",
    "\n",
    "* Bilinear provides a simple baseline with error proportional to local curvature $(M)$.\n",
    "\n",
    "* Niu uses directional, asymmetric weights; when edge detection is accurate and gradients are modest, it can reduce across-edge blur, but the asymmetric weights introduce a linear-gradient term that can dominate in high-$L$ regions, making the worst-case bound loose and sometimes worse than bilinear.\n",
    "\n",
    "* Lien achieves the tightest curvature-based bound when the edge direction is correctly identified, effectively reducing the interpolation distance from $\\sqrt{2}$ to 1. Misclassification degrades performance back toward bilinear.\n",
    "\n",
    "* Wu's distance weighting improves empirical behavior but, under the pure curvature bound, shares the same worst-case scaling as bilinear in symmetric configurations.\n",
    "\n",
    "* Kiku offers the strongest empirical performance by iteratively refining the residual, but its bound relies on observed geometric error decay and thus is not a strict worst-case guarantee.\n",
    "\n",
    "All of these reconstruction bounds share the same fundamental limitation noted in §3.2.2: they assume smoothness $(M \\ll 510)$ and do not account for aliasing introduced by CFA sampling itself. For pathological high-frequency patterns where discrete second derivatives approach their theoretical maximum, the Taylor-based smoothness assumptions break down and only the trivial range-based bound (255 per channel) remains valid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "references",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Bayer, B. E. (1976). Color imaging array. U.S. Patent No. 3,971,065.\n",
    "\n",
    "Dubois, E. (2005). Frequency-domain methods for demosaicking of Bayer-sampled color images. IEEE Signal Processing Letters, 12(12), 847-850.\n",
    "\n",
    "Gunturk, B. K., Glotzbach, J., Altunbasak, Y., Schafer, R. W., & Mersereau, R. M. (2005). Demosaicking: color filter array interpolation. IEEE Signal Processing Magazine, 22(1), 44-54.\n",
    "\n",
    "Hirakawa, K., & Parks, T. W. (2005). Adaptive homogeneity-directed demosaicing algorithm. IEEE Transactions on Image Processing, 14(3), 360-369.\n",
    "\n",
    "Kimmel, R. (1999). Demosaicing: Image reconstruction from color CCD samples. IEEE Transactions on Image Processing, 8(9), 1221-1228.\n",
    "\n",
    "Li, X., Gunturk, B., & Zhang, L. (2008). Image demosaicing: A systematic survey. In Visual Communications and Image Processing 2008 (Vol. 6822, p. 68221J). International Society for Optics and Photonics.\n",
    "\n",
    "Malvar, H. S., He, L. W., & Cutler, R. (2004). High-quality linear interpolation for demosaicing of Bayer-patterned color images. In 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing (Vol. 3, pp. iii-485). IEEE.\n",
    "\n",
    "Nyquist, H. (1928). Certain topics in telegraph transmission theory. Transactions of the American Institute of Electrical Engineers, 47(2), 617-644.\n",
    "\n",
    "Shannon, C. E. (1949). Communication in the presence of noise. Proceedings of the IRE, 37(1), 10-21.\n",
    "\n",
    "Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004). Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image Processing, 13(4), 600-612.\n",
    "\n",
    "Zhang, L., Wu, X., Buades, A., & Li, X. (2011). Color demosaicking by local directional interpolation and nonlocal adaptive thresholding. Journal of Electronic Imaging, 20(2), 023016.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Niu, Y., Ouyang, J., Zuo, W., & Wang, F. (2018). Low cost edge sensing for high quality demosaicking. IEEE Transactions on Image Processing, 28(5), 2415–2427. Retrieved from https://arxiv.org/pdf/1806.00771\n",
    "\n",
    "\n",
    "Wu, J., Anisetti, M., Wu, W., Damiani, E., & Jeon, G. (2016). Bayer demosaicking with polynomial interpolation. IEEE Transactions on Image Processing, 25(11), 5369–5382. Retrieved from https://air.unimi.it/bitstream/2434/440833/4/2434-440833.pdf\n",
    "\n",
    "\n",
    "Lien, C.-Y., Yang, F.-J., & Chen, P.-Y. (2017). An efficient edge-based technique for color filter array demosaicking. IEEE Sensors Journal, 17(13), 4067–4074. Retrieved from https://ieeexplore.ieee.org/abstract/document/7931560/\n",
    "\n",
    "\n",
    "Kiku, D., Monno, Y., Tanaka, M., & Okutomi, M. (2016). Beyond color difference: Residual interpolation for color image demosaicking. IEEE Transactions on Image Processing, 25(3), 1288–1300. Retrieved from https://ieeexplore.ieee.org/abstract/document/7383296/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55534a62",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad2d4deb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7891302",
   "metadata": {},
   "source": [
    "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0232583\n",
    "\n",
    "https://hal.science/hal-00204920/file/AlleyssonetalTIP05.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76af4fac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
